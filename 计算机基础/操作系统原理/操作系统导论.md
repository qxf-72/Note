<center>
<img src="https://picture-in-md.oss-cn-guangzhou.aliyuncs.com/2024-07-11_083427.jpg" width="500" />
</center>


 
# 主题一 虚拟化

## 抽象：进程

操作系统通过虚拟化，提供有多个 CPU 的假象——时分共享 CPU 技术。而实现 CPU 虚拟化需要一些**低级机制（分时机制等）** 和 **高级智能（CPU 调度策略）**。

<br/>

**进程的机器状态**
- 内存（进程可以访问的内存称为地址空间，是进程一部分）
- 寄存器

> 进程的机器状态指的是 进程在执行过程中的当前状态，是操作系统**进行上下文切换时需要保存和恢复的关键信息**，以确保进程在重新调度执行时能够从上次中断的地方继续执行。


<br/>



操作系统必备的 API 如下：
- 创建：创建新的进程
- 销毁：可以强制销毁进程
- 等待：进程停止运行
- 获取状态：获得进程状态信息

> 进程API补充
> - `fork`：用于创建新的进程，调用 fork 之后，从调用位置开始，子进程开始和父进程一起开始运行（相当于复制了一份父进程）。fork 有返回值，对于父进程，返回值为子进程的 PID；对于子进程返回值为0；子进程一开始与父进程共用地址空间，**如果子进程之后有使用内存的需要，才会复制一份自己的地址空间**。
> - `wait`：在父进程中调用 wait，父进程会进入阻塞状态，等子进程执行完毕后，再继续执行。
> - `exec`：让子进程执行和父进程不同的程序，给定可执行程序名字以及需要的参数，exec 会从可执行程序加载代码和静态数据，并覆写自己代码段、堆、栈以及其他内存空间也会重新初始化。


<br/>


操作系统**创建进程的过程**
- 将代码和所有静态数据加载到内存；现代操作系统**惰性执行**该过程，仅加载会运行的代码片段。
- 为程序 运行时栈、堆 分配内存。
- 执行一些其他初始化任务，特别是IO相关的任务；在UNIX系统中，默认每个进行有3个打开的文件描述符（标准输入、输出和错误）。

<center>
<img src="https://picture-in-md.oss-cn-guangzhou.aliyuncs.com/2023-03-03_085548.png" width="500" />
</center>


<br/>


**进程状态**
- 运行（running）：正在处理器运行。
- 就绪（ready）：准备好运行，等待调度。
- 阻塞（blocked）：执行了其他操作（如IO请求），直到其他时间完成才准备运行。

<center>
<img src="https://picture-in-md.oss-cn-guangzhou.aliyuncs.com/2023-03-03_085953.png" width="300" />
</center>

> 除了三个进程状态以外，还有一些其他状态：
>    - 初始状态（initial）：进程正在创建
>    - 最终状态（final）：已退出但未被清理（可以检测进程是否执行成功）


<br/>

操作系统管理进程需要的数据结构：
- 进程列表（process list）：为了跟踪每个进程的状态，操作系统会为所有就绪的进程保留某种进程列表。
- 上下文切换（context switch）：将进程寄存器的值保存到内存，通过恢复寄存器也可以恢复运行该进程。

---


<br/>


<br/>


## 机制：受限直接执行

### 基本技巧：受限直接执行

直接执行就是，直接在CPU上运行一个程序，但这样有两个问题：
   - 操作系统如何保证，程序不做任何操作系统限制做的事。
   - 操作系统如何停止一个进程，并切换到另一个进程。

---

<br/>




### 问题1：受限制的操作

引入两种处理器模式：
   - 用户模式（user mode）：运行代码会受到限制（例如，不能发出 IO 请求）。
   - 内核模式（kernel mode）：操作系统就以这种模式运行，可以做进行特权操作。

要执行系统调用，程序执行特殊**陷阱（trap）指令**，该指令同时跳入内核并升级到内核模式；完成操作后，操作系统调用一个**陷阱返回指令**，权限降为用户模式。

在 x86上，处理器会将 PC、标志和其他寄存器压入内核栈中，返回陷阱时，从栈弹出这些值。


---


<br/>



### 问题2：进程之间的切换

- 协作方式：操作系统相信进程会合理运行；OS 通过等待系统调用，或者某种非法操作，重新获得系统控制权。
- **非协作方式**：**时钟中断**，时钟设备可以每隔几毫秒产生一次中断，产生中断时，进程停止运行，操作系统预先配置的中断处理程序运行，OS 重新获得控制权。

---


<br/>


<br/>


## 进程调度：介绍

### 调度指标

$$
T_{周转时间}=T_{完成时间}-T_{到达时间}
$$

周转时间是一个性能指标。

---

<br/>


### FIFO

- 简单，易于实现。
- **护航效应**：一些耗时较少的潜在资源消费者被排在重量级消费者之后。

<center>
<img src="https://picture-in-md.oss-cn-guangzhou.aliyuncs.com/2023-03-05_091524.png" width="600" />
</center>


---

<br/>



### 最短任务优先 SJF

**假设所有工作同时到达**的最优算法，但是实际上并不是所有任务会在同一时间到达。

<center>
<img src="https://picture-in-md.oss-cn-guangzhou.aliyuncs.com/2023-03-05_091845.png" width="600" />
</center>


---


<br/>



### 最短完成时间优先 STCF

每当新工作进入系统时，确定剩余工作是按和新工作中谁剩余时间最少，然后调度工作。

实现起来相当困难，对于一个新进入的工作很预测到其完成工作的所需时间

---

<br/>


### 新度量指标：响应时间

看重进程的**首次运行的时间**。

$$
T_{响应时间}=T_{首次运行}-T_{到达时间}
$$

---

<br/>


### 轮转

- 各进程轮转调度。
- 一个之间片内值运行一个工作，时间片也被称为**调度量子**。
- 时间片长度必须是时钟中断周期的倍数。
- 时间片长度问题：时间片太短会因为上下文切换影响整体性能，太长会让系统不能及时响应。

---


<br/>


<br/>



## 调度：多级反馈队列

**<span style="background:#fff88f">多级反馈队列 MLFQ</span>**（Multi-level Feedback Queue）**综合考虑周转时间和响应时间**。 

### MLFQ 基本规则

MLFQ有许多独立队列，每个队列有不同优先级，同一队列任务优先级相同，优先级高的队列中的任务优先执行：

- 规则1：如果 A 优先级 > B 优先级，运行 A 
- 规则2：如果 A 优先级 = B 优先级，轮转运行 

---

<br/>


### MLFQ 改变优先级

MLFQ调度策略关键在于如何设置优先级，MLFQ观察任务行为设置优先级：

- 规则3：工作进入系统时，放在最高优先级（保证响应时间）
- 规则4a：工作用完整个时间片后，降低一个优先级
- 规则4b：如果在其工作时间片内主动释放CPU，优先级不变

规则4改变优先的方法产生2个问题：

- 饥饿问题：系统如果有太多交互工作，就会不断占用 CPU，长工作无法得到 CPU 资源 。
- 恶意程序问题：某个进程可以在时间片用完之前，可以调用一个 IO 操作（访问一个无关的文件），就可以保持较高优先级，不断占用 CPU 资源 。

---

<br/>



### 提升优先级

尝试改变之前的规则，**避免饥饿问题**：
- 规则5：经过一段时间 S，就会将系统中所有工作重新加入最高优先级队列

S 被称为“巫毒常量”，S 设置太高，长工作会饥饿，S 太短，交互型工作得不到合适 CPU 时间比例。

---

<br/>

### 更好的计时方式

调度程序**记录一个进程在某一层中消耗的时间**，不论是一次用完还是多次用完：

- 规则4：一旦工作用完某一层的时间配额，就降低一个优先级（无论中间是否放弃CPU）

<br/>


<span style="background:#fff88f">**总结MLFQ的规则**</span>
<center>
<img src="https://picture-in-md.oss-cn-guangzhou.aliyuncs.com/2023-03-09_094139.png" width="600" />
</center>


---


<br/>


<br/>




## 调度：比例份额

比例份额调度程序，也被称为公平份额调度程序，比例份额算法基于简单的想法：**确保每个工作都能获得一定比例的 CPU 时间**，而不是优化周转时间和响应时间。

现介绍比例份额调度的一个例子——彩票调度（lottery scheduling）。

### 彩票调度基本概念

彩票数（ticket）代表进程占有某个资源的份额，**通过抽取彩票来决定哪一个程序运行**：调度程序知道总共彩票数，然后抽取一个数字，运行拥有对应数字的彩票的程序。

**彩票调度最精彩的地方在于利用率随机性**，采用随机的方式既可靠，又简单，随机方法相对于传统的决策方法至少具有三方面优势：
- 避免奇怪的边界情况 。
- 轻量，几乎不需要记录任何状态 。
- 速度很快 。


---

<br/>

### 彩票机制

彩票调度提供了一些机制，以不同且有效的方法来调度彩票：
- 彩票货币概念：彩票用户可以将自己的彩票换成某种货币，分配给自己不同的工作（本质上还是彩票，就是把自己的彩票以不同份额分出去），操作系统会自动将这些货币兑换回彩票。
- 彩票转让机制：一个进程可以将自己的彩票临时交给另一个进程。
- 彩票通胀：进程临时提高或降低自己的彩票数量，只能用于进程之间相互信任的环境。

---

<br/>


### 彩票调度实现

彩票调度实现简单，只需要一个随机数生成器选择中奖彩票和一个记录系统中所有进程的数据结构（列表），以及彩票总数。假定用列表来记录进程，如下图：

<center>
<img src="https://picture-in-md.oss-cn-guangzhou.aliyuncs.com/2023-03-09_100032.png" width="600" />
</center>



首先从彩票总数中选择一个随机数（中奖号码），然后遍历链表，用一个计数器帮助找到中奖者，从前往后遍历列表，把进程彩票数加到计数器上，当计数器的值超过中奖号码时，即当前进程就是要调度的进程。为了这一过程更快执行，建议把列表项按照彩票数递减排序。

当每个工作有相同数量的彩票时，假定他们具有相同运行时间 R，此时由于彩票调度的随机性，一个工作可能先于另一个工作完成。

对于只有两个工作的例子。定义**不公平指标** $U=\frac{\text{较先工作完成时刻}}{\text{另一个工作完成时刻}}$ 来量化区别

<center>
<img src="https://picture-in-md.oss-cn-guangzhou.aliyuncs.com/2023-03-09_100856.png" width="400" />
</center>



只有工作执行很多时间片时，才能拿得到期望结果，且对于**如何分配彩票，可以由用户自己分配，彩票分配问题没有最佳答案**。

---


<br/>



### 步长调度

由于彩票调度利用随机性比较简单，但是偶尔并不能产生正确的比例，所以提出了**步长调度——一种确定性的公平分配算法**。


系统中**每个工作都有自己的步长**，这个值和票数成反比，另外系统还要记录每个进程的行程值，在需要调度时，**优先调度拥有最小行程的进程**，并在**运行之后在该进程的行程值加上一个它的步长**。

彩票调度有一个步长调度没有的优势——不需要全局状态，另外**当一个新的进程进入系统时，步长调度如何设置初始行程值也是一个问题**，彩票调度能够更合理处理新加入的进程。


---

<br/>


<br/>


## 多处理器调度

多处理器带来的主要困难——重写应用程序，使之能够**并行执行**，使用多线程，将工作分散到多个 CPU 上。

### 多处理器架构

多处理器和单处理器的核心区别——对硬件缓存的使用，以及多处理之间共享数据的方式。


缓存是基于局部性的概念：

- 时间局部性：一个数据被访问后，很有可能在不久之后被再次访问。
- 空间局部性：访问数据时，很可能访问其地址周边的数据；根据局部性，硬件系统可以很好预测哪些数据可以放入缓存，从而进行更好。

<br/>

多处理调度需要考虑的问题有：
- **缓存一致性**：当一个CPU的进程要内存中的值，会先在在缓存中更新，然后缓慢写入内存，此时如果另一个CPU的进程读取内存，就会得到旧的值。基本解决方案：监控内存访问，**每个缓存监控其他所有缓存和内存总线，发现其他缓存的数据更新，会作废本地副本或进行更新**。
- **同步问题**：跨CPU共享数据时，需要使用互斥原语，来保证正确性。
- **缓存亲和度**：一个进程尽量在相同的CPU上执行，避免缓存要重新加载数据。

---


<br/>


### 单队列调度

将所有需要调度的工作放入一个独立的队列里面，称为**单队列多处理器调度 SQMS**（Single Queue Multiprocessor Scheduling）。

SQMS优势是能够从单个CPU调度程序很简单地发展而来，但是有几个明显短板：

- 缺乏可拓展性：在各个 CPU 上面运行时，调度程序需要通过锁来保证原子性。
- 可能带来巨大性能损失：随着单个锁争用增加，系统花费越来越多时间在锁的开销上。
- 缺乏缓存亲和性：每个 CPU 简单地从队列选取下一个工作执行，可能会导致同一个工作不断在不同 CPU 之间转移。

<center>
<img src="https://picture-in-md.oss-cn-guangzhou.aliyuncs.com/2023-03-09_150129.png" width="400" />
</center>

<center>
<img src="https://picture-in-md.oss-cn-guangzhou.aliyuncs.com/2023-03-09_150148.png" width="400" />
</center>



为了解决缓存亲和的问题，大多数 SQMS 引入了一些亲和机制，在保持一些工作的亲和度的同时，可能需要牺牲其他工作的亲和度来实现负载均衡。


<center>
<img src="https://picture-in-md.oss-cn-guangzhou.aliyuncs.com/2023-03-09_150413.png" width="400" />
</center>


---


<br/>




### 多队列调度

**多队列多处理器调度 MQMS**（Multi-Queue Multiprocessor Scheduling）包含多个队列，每个队列可以使用不同调度规则，避免了单队列由于数据共享及同步带来的问题。

MQMS 比 SQMS 具有明显优势，天生更具有可拓展性，具有良好的缓存亲和度，但是**容易导致负载不均**。

<center>
<img src="https://picture-in-md.oss-cn-guangzhou.aliyuncs.com/2023-03-09_151145.png" width="500" />
</center>



为了负载均衡，可以让工作移动，这种技术称为**迁移**，有些时候需要不断迁移一个或多个工作；

一个基本的方法是采用一种技术——**工作窃取（work stealing）**：工作量较少的队列不定期探查其他队列是不是比自己工作多，如果被探查的队列的工作明显更多，就会窃取其中的工作，实现负载均衡。


---

<br/>


### Linux 调度策略

Linux 系统在构建多处理器调度程序方面，存在 3 种不同的调度策略：

- **O(1)调度程序**：采用多队列，基于优先级，随时间推移改变进程优先级，然后调度最高优先级进程，交互性得到了特别关注。
- **完全公平调度程序CFS**：采用多队列，采用比例调度方法（类似步长调度）。
- **BF调度程序**：采用单队列，基于比例调度。


---


<br/>


<br/>



## 抽象：地址空间

一个进程的地址空间包含运行程序的所有内存状态，主要包含 代码、栈和堆。代码是静态的，放在地址空间的低地址，而栈和堆在运行时可能会增长，一般堆分配在地址空间低地址方向靠近静态代码，而栈放在地址空间底部，中间保留未分配的地址。


<center>
<img src="https://picture-in-md.oss-cn-guangzhou.aliyuncs.com/2023-03-09_165021.png" width="400" />
</center>


**虚拟内存（VM）系统** 的目标：
- 透明：操作系统让程序看不见，好像自己拥有私有的物理内存，操作系统在幕后完成了所有工作，让不同工作复用内存。
- 效率：在实现高效率虚拟化时，操作系统不得不依靠硬件支持。
- 保护：确保进程收到保护，不会收到其他进程影响，在进程之间提供隔离。

虚拟内存是操作系统一个重要子系统，负责为程序提供了一个巨大的、稀疏的、私有的地址空间的假象，其中保存了程序的所有指令和数据，操作系统在专门硬件的帮助下，通过一个虚拟内存的索引，将其转化为物理地址。

<br/>


**内存操作API**

- `malloc()`和`free()`不是系统调用，而是库调用，malloc管理虚拟地址空间，它本身就是建立在一些系统调用之上。
- 一个系统调用叫做brk，用来改变程序分断（break）的位置：堆结束的位置，需要一个参数——新分断的地址，另一个调用sbrk参数是一个增量。

---


<br/>


<br/>




## 机制：地址转换

在实现 CPU 虚拟化时，遵循的一般准则为**受限直接访问 LDE**（Limited Direct Execution）。高效和控制是现代操作系统两个主要目标，在实现虚拟内存时，追求类似的战略
- 高效决定了要需要硬件的支持
- 控制意味着操作系统要确保应用程序只能访问自己的内存空间


基于硬件的地址转换，通过提供底层机制来提高效率，操作系统必须在关键位置介入，设置好硬件，记录被占用和空闲的内存位置。


### 动态重定位

每个 CPU 有两个硬件寄存器：基址（base）寄存器、界限（bound）寄存器；程序执行时，操作系统决定物理内存的实际加载位置，将起始地址放在基址寄存器，进程地址通过 以下方式转化为物理地址：

$$physical\  address=virtual\ address+base$$


界限寄存器有两种使用方式：

- 记录地址空间大小 
- 记录地址空间结束的地址

基址寄存器和界限寄存器的硬件结构位于芯片中，将该部分统称为**内存管理单元MMU**（Memory Management Unit）。
> 在早期，一些系统采用纯软件的重定位方式，基本技术称为静态重定位，其中一个加载程序接手将要运行的可执行程序，将地址重写到物理内存期望的偏移地址
> 静态重定位的主要问题有
> - 不提供访问保护，一般需要硬件支持来实现真正的访问保护
> - 定位一旦完成，很难将内存空间重定位到其他位置

---


<br/>


### 操作系统行为

硬件支持和操作系统管理结合在一起，实现VM，在一些关键时刻操作系统必须介入
- 进程创建时，为进程的地址空间找到内存空间
- 进程终止时，回收内存
- 上下文切换时，保存和恢复基址和界限寄存器
- 提供异常处理程序

以上提到的将整个地址空间作为一个整体重定位到内存中存在内存空间浪费的问题，由于栈区和堆区不大时，中间的空闲内存称为**内部碎片**（internal fragmentation）

---

<br/>


<br/>


## 分段

**为了解决内部碎片的问题，分段（segmentation）应运而生**，基本思想就是在 MMU 中引入不止一对基址和界限寄存器；分段的机制可以让操作系统将不同的段投放到不同的物理内存区域

此时物理地址的计算方式不同于之前了，由于不是将整个地址空间映射到物理内存，要用虚拟地址相对于分段起始的值的偏移量，加上基址得到物理内存地址


### 标记引用的段

硬件在地址转换时需要知道地址引用的是哪一个分段，可以采用以下方式：

- 显式（explict）方式：是常用的方法，用虚拟地址开头的几位来标记不同的段

<center>
<img src="https://picture-in-md.oss-cn-guangzhou.aliyuncs.com/2023-03-16_090401.png" width="600" />
</center>




- 隐式方式：通过地址的产生方式来确认分段，如果地址有由程序计数器 PC 产生，地址在代码段，如果基于栈或基址指针，在栈段，其余在堆段

---

<br/>


### 栈地址计算
由前面可知，栈的地址增长方向为反向，所以硬件还需要知道分段的增长方向（可用一位进行区分）
反向增长的分段的地址转换也有所不同：要访问的虚拟地址减去最大段的虚拟地址得到偏移量（为一个负数），然后加上基址得到物理内存地址

### 内存共享

在内存中共享一些分段可以节约内存空间，为了实现共享需要为每个分段添加一个位，标识分段中的数据是否可读写、可执行。

分段内容为为只读才能被多个进程共享。

<center>
<img src="https://picture-in-md.oss-cn-guangzhou.aliyuncs.com/2023-03-16_091400.png" width="600" />
</center>

以上例子只有很少的几个分段，这种方式称为粗粒度（coarse-grained），相对的，把地址空间划分为大量的段称为细粒度（fine-grained）。

操作系统需要管理物理内存的空闲空间，一般会遇到的问题是，物理内存很快充满许多空闲空间的小洞，因此很难分配给新的段或扩大已有的段，这种问题就是**外部碎片**（external fragmentation）。

<center>
<img src="https://picture-in-md.oss-cn-guangzhou.aliyuncs.com/2023-03-16_092108.png" width="500" />
</center>



一种简单的做法就是利用空闲列表管理算法，但是无论算法多么精妙都**无法完全消除外部碎片**，只能试图减小。

---

<br/>


<br/>


## 空闲空间管理

在内存管理空闲空间的数据结构通常被称为**空闲列表**（free list），该结构中包含了管理内存空间中所有空闲块的引用。


### 底层机制

**简单机制——分隔与合并**

当申请内存时，会找到满足要求的空闲内存块，如果没有找到就返回 NULL，如果申请的空间比选中的空闲块要小，就执行**分隔（splitting）**，在空闲块中分隔出申请的内存，同时对空闲列表进行修改。


<center>
<img src="https://picture-in-md.oss-cn-guangzhou.aliyuncs.com/2023-03-16_101541.png" width="600" />
</center>



对于释放的内存空间，如果不考虑合并就会把连续空闲空间分隔成多份，在上面的例子中如果在释放申请的内存之后没有进行**合并**，结果如下

<center>
<img src="https://picture-in-md.oss-cn-guangzhou.aliyuncs.com/2023-03-16_101904.png" width="600" />
</center>



这样会导致及时有足够的空闲空间，也有可能分配空间失败，为避免该问题，分配程序会在释放内存时考虑进行合并可用空间

<center>
<img src="https://picture-in-md.oss-cn-guangzhou.aliyuncs.com/2023-03-16_102143.png" width="400" />
</center>



<br/>

**追踪已分配空间——头块**

大多数分配程序会**在已分配内存之前设置一个头块**，保存额外信息，其中至少包含分配的空间大小和一个幻数
> 幻数是一种特殊的数值，用于表示某些系统的状态或结构。在操作系统的空闲空间管理中，幻数是一种标识符，用于检测内存空间是否被正确分配和释放。在分配内存空间时，在头块中写入一个特定的幻数值，然后在释放内存空间时，检查头块中的幻数值是否与预期相符。如果不相符，说明内存空间可能被破坏或越界

<center>
<img src="https://picture-in-md.oss-cn-guangzhou.aliyuncs.com/2023-03-16_102550.png" width="650" />
</center>



进行空间释放时，实际上是释放头块大小加上分配给用户的空间大小。


<br/>



**嵌入空闲列表**

空闲列表其实是在空闲空间本身里面建立的，空闲列表的结构如下：

<center>
<img src="https://picture-in-md.oss-cn-guangzhou.aliyuncs.com/2023-03-16_102941.png" width="600" />
</center>

假设堆建立在某块空闲空间上，这块空间通过系统调用 `mmap()` 获得，初始化堆的代码可能如下：

<center>
<img src="https://picture-in-md.oss-cn-guangzhou.aliyuncs.com/2023-03-16_103316.png" width="650" />
</center>



下图形象表示了空闲内存中的空闲列表

<center>
<img src="https://picture-in-md.oss-cn-guangzhou.aliyuncs.com/2023-03-16_103528.png" width="700" />
</center>


---

<br/>


### 基本策略

有了底层机制后，现在考虑管理空闲空闲的基本策略：
- 最优匹配（bast fit）：遍历整个空闲列表，找到和请求空间一样或大于的空闲空间，然后返回其中最小的一块。在遍历查找满足要求的空间时付出较高性能代价。
- 最差匹配（worst fit）：查找最大的空闲块，然后分割得到所要分配的空间，该算法尝试在空闲空间中保留较大的空闲块而不是向最优匹配会分割剩下很小空闲块；同样需要遍历整个空闲列表，且会导致过量碎片。
- 首次匹配（first fit）：找到第一个满足分配条件的块就进行分配；具有速度优势，但会让列表开头部分有很多小块。
- 下次匹配（next fit）：采取和首次匹配一样的策略，但是多维护一个指针，指向上次查找结束的位置，并从该位置开始查找；避免了对列表开头频繁的分割。

---

<br/>


### 其他方式

**分离空闲列表**

基本想法：如果某个引用程序经常申请一种（或几种）大小的内存空间。就用一个独立的空闲列表管理这样大小的对象，其他大小的请求交给更通用的内存分配程序。

可以解决碎片的问题，而且列表查找过程简单，但是新的问题是：需要拿出多少内存来专门为某种大小请求服务。

**厚块分配程序（slab allocator）** 处理了这个问题：内核在启动时，为可能频繁请求的内核对象（例如，锁和文件系统 的inode）创建对象缓存，分离特定大小的空闲列表，当某个缓存的空闲空间快耗尽时，就向通用内存分配程序申请一些内存厚块（总量是页大小和对象大小的公倍数），如果给定厚块没有对象引用，就从专门的分配程序回收空间。
> 厚块分配程序将类中中的空闲对象保持在预初始化的状态，避免了频繁的初始化和销毁，显著降低了开销。
> 
> 对象在之前被分配出去时已经进行过初始化操作，然后在被释放回厚块分配程序时没有被销毁，而是保留在空闲列表中。所以当再次需要分配这个对象时，就不需要再进行初始化操作。

<br/>


**伙伴系统**

二分伙伴分配程序为了让空闲合并变得简单，具体做法是：有内存分配请求时，空闲空闲被递归地一分为二，直到刚好可以满足请求的大小。

<center>
<img src="https://picture-in-md.oss-cn-guangzhou.aliyuncs.com/2023-03-16_111557.png" width="500" />
</center>


当块被释放时，检查伙伴是否空闲，空闲就合并，合二为一再向上回溯检查。

---


<br/>


<br/>


## 分页：介绍

将空间分为长度不同的分片之后，空间本身会碎片化，随着时间推移，分配内存会变得困难；现在讨论第二种空间管理方法——分页，基本思想为：将地址空间分割为固定大小的单元，物理内存也相应的分成定长的页帧（page frame）。


分页相对于分段的优点有：
- 灵活性：高效提供地址空间抽象，无论进程如何使用地址空间（无须考虑栈和堆的增长方向）
- 空闲空间管理简单

为了记录地址空间的每个虚拟页放在物理内存的位置，需要为每个进程保存一个数据结构——**页表**（page table），页表是每个进程的数据结构（**每个进程地址空间独立，每个进程有独立页表**）。虚拟地址号可分为两个部分：**虚拟页面号 VPN**（virtual page number）和 **偏移量**（offset），如下：

<center>
<img src="https://picture-in-md.oss-cn-guangzhou.aliyuncs.com/2023-03-16_120237.png" width="400" />
</center>



在进行地址转换时，只需要转换VPN，偏移量不需要做改动，如下所示：
<center>
<img src="https://picture-in-md.oss-cn-guangzhou.aliyuncs.com/2023-03-16_120405.png" width="350" />
</center>




页表可以变得很大，因此每个进程的页表存储在内存中。



### 页表的内容

页表最简单的形式称为线性页表（linear page table），就是一个数组，通过VPN检索数组，在索引处查找**页表项（PTE）**，以便找到期望的物理帧号（PFN）
对于PTE的内容，其中有多标志位：

- 有效位（valid bit）：指示特定地址转换是否有效，可以简单地将地址空间中为使用的页面标志为无效，不需要分配物理帧，从而节省内存
- 保护位（protection bit）：表明页面是否可以读取、写入或执行
- 存在位（present bit）：表示页是在物理存储器还是在磁盘上
- 脏位（dirty bit）：表示页面存入内存之后是否被修改过
- 参考位（reference bit，访问位accessed bit）：用于追踪页是否被访问

以下为x86架构的示例页表项
<center>
<img src="https://picture-in-md.oss-cn-guangzhou.aliyuncs.com/2023-03-16_142621.png" width="600" />
</center>


---

<br/>


### 分页地址转换过程
首先执行以下功能，先与掩码进行与运算，选中VPN位，VPN位再右移得到正确的整数虚拟页码，然后找到PTE
> 这里为什么要用掩码进行与运算，而不是直接右移，我上网搜索也没找到确切答案
> 一种可能是，先用掩码在右移更灵活，当 VPN 不是在最高的几位时，直接右移得到的不是 VPN。

<center>
<img src="https://picture-in-md.oss-cn-guangzhou.aliyuncs.com/2023-03-16_142908.png" width="500" />
</center>



先进行检查，然后PFN加上偏移量
<center>
<img src="https://picture-in-md.oss-cn-guangzhou.aliyuncs.com/2023-03-16_143329.png" width="600" />
</center>

---

<br/>


<br/>


## 分页：快速地址转换 TLB

页表一般存储在内存中，所以在进行虚拟地址转换时，需要一次额外的内存访问，带来较高的性能开销，为了加速地址转换过程，增加了**地址转换旁路缓冲存储器（translation-lookaside bufffer）TLB**，其实就是硬件缓存（cache）。

### TLB 基本算法

<center>
<img src="https://picture-in-md.oss-cn-guangzhou.aliyuncs.com/2023-03-16_154627.png" width="700" />
</center>



当 TLB 未命中时，需要额外内存引用，开销较大。得益于时间局部性和空间局部性，一般情况下 TLB 命中率较高。

---

<br/>


### 处理 TLB 未命中

更现代的计算机基本都使用精简指令集，有软件管理 TLB（software-managed TLB），当 TLB 未命中时，硬件系统抛出异常，指令流暂停，进入内核模式，跳转到陷阱处理程序（查找页表，用特权指令更新 TLB）。

这里从陷阱返回不同于别的系统调用，TLB 未命中处理返回之后会继续执行导致陷阱的指令，而以前提到的是继续执行陷入操作系统之后那条指令。

在运行 TLB 未命中处理代码时，需要额外注意引起 TLB 未命中的无限递归（即在 TLB 处理程序的代码 TLB 未命中），可以把处理程序直接放到物理内存，此时不需要内存转换，或者在 TLB 保留一些项，记录永久有效的地址转换。

---

<br/>


### TLB 的内容

典型的 TLB 有32、64或128项，并且是**全相联**的。所以硬件会并行查找 TLB，一条 TLB 内容可能项以下这样：
$VPN\ |\ PFN\ | \ 其他位$

TLB 通常有一个有效位，用来指出 TLB 项是不是有效的地址映射，不同于页表项 PTE 中的有效位。

---

<br/>


### 上下文切换对 TLB 的处理

由于TLB中的内容只对当前的进程有效，发生上下文切换时，需要保证即将运行的进程不会误读之前进程的地址映射，可行的解决方案如下：

- 清空TLB：在上下文切换时flush TLB，本质上把所有有效位设为0
- 地址空间标识符ASID：用来标识不同进程，类似PID，长度比PID短，一般是8位，硬件需要知道当前哪一个进程在运行，需要在某个特权寄存器保存当前进程ASID

以下为 MIPS R4000简化后的 TLB 项：

<center>
<img src="https://picture-in-md.oss-cn-guangzhou.aliyuncs.com/2023-03-16_163833.png" width="700" />
</center>



预期有20位的VPN，但实际上用户地址只占地址空间一半（其余留给内核），故只有19位；另外全局为G标识这个页是否全部进程共享，如果是就会忽略ASID
MIPS 的 TLB 通常有32项或64项，操作系统可以设置一个被监听的寄存器，告知硬件需要为其保留多少 TLB 项，用于关键时期使用的代码和数据（例如，TLB 未命中处理代码）。

---

<br/>


### TLB 替换策略

当向 TLB 插入一个新的项且 TLB 已满时，会替换一个旧项，对于选择被替换的项有两种策略：
- 最近最少使用LUR（least-recently-used）：利用了内存引用流的局部性
- 随机策略：随机选择一个项进行替换，简单并且可以避免一些**极端情况（例如，一个程序循环访问 $n+1$ 页，而 TLB 中只有 $n$ 个项，使用 LRU 策略的话每次都会触发 TLB 未命中）**。

---

<br/>


### 分页：较小的页表

之前讨论过，分页会导致需要存储大量页表，消耗内存太多，为了解决该问题，有以下解决方式：


**简单解决方式——更大的页**

每页的容量更大时，页表的长度就越小，但是这样就和刚开始将整个地址空间映射到物理地址一样会导致内部碎片问题
> 许多体系结构（MIPS、SPAOC、x86-64）支持多种页大小，目的为了减少TLB的压力，例如应用程序可以把常用的数据结构放入一个大的页里面，提高TLB命中率；但是这种方式和分段一样，会使得虚拟内存管理变得复杂


<br/>


**另外一种解决方法——考虑分段和分页的结合**

为每个逻辑分段（例如，代码、栈、堆）各提供一个页表，每个逻辑分段的基址——页表的起始物理地址，界限——页表的结尾；虚拟地址结果如下：

<center>
<img src="https://picture-in-md.oss-cn-guangzhou.aliyuncs.com/2023-03-18_104738.png" width="600" />
</center>



与线性页表相比，杂合方法让**未分配的页不占用页表的空间**
<center>
<img src="https://picture-in-md.oss-cn-guangzhou.aliyuncs.com/2023-03-18_105136.png" width="400" />
</center>



地址转换方法如下：
<center>
<img src="https://picture-in-md.oss-cn-guangzhou.aliyuncs.com/2023-03-18_105341.png" width="500" />
</center>


<br/>


**多级页表（multi-level page table）**

不依赖分段，而是将线性页表变成了类似树的结构，**许多现代操作系统采用该方法**。

其核心思想为：将页表分为页大小的单元，然后用**页目录 PDE** 访问该页，**如果整个页的页表项都无效就不分配该页的页表**（即在页目录中将指向该页的项标记为无效）；PDE 至少需要包括有效位（valid bit）和页帧号。

<center>
<img src="https://picture-in-md.oss-cn-guangzhou.aliyuncs.com/2023-03-18_110204.png" width="700" />
</center>


多级页表是有成本的，其一个缺点是在TLB未命中时，需要在内存中加载多次（多级页表是时间和空间折中的产物），另外一个缺点是复杂性：处理页表查找比线性表查找复杂
当目录放不入一个页时，就需要采用超过两级的页表了，一个例子如下：

<center>
<img src="https://picture-in-md.oss-cn-guangzhou.aliyuncs.com/2023-03-18_111135.png" width="600" />
</center>



反向页表——其中的项代表每个物理页，项中的内容指明哪些进程在使用此页，以及该进程的哪个虚拟页映射到物理页


---

<br/>


<br/>


## 机制：超越物理内存

程序的地址空间可能很大，而且每个进程都有独立的地址空间，所以物理内存可能存储不下所有地址空间，为了方便和易用性，可以把部分内存的页存放到硬盘里面。

### 交换空间

交换空间（swap space）是在硬盘中开辟的用于物理页移入和移出的空间。

对于程序，可以将一部分有效页放在内存，剩下的（没有被访问）放在交换空间。

现代操作系统中，二进制代码按需求一页一页被加载，如果系统需要在物理内存腾出空间来满足其他需要，可安全的使用代码页的内存空间，因为稍后它又可从硬盘加载。

---

<br/>


### 存在位

利用页表项的存在位（present bit）来记录页是否存在内存中，如果访问的页不在内存中，就会出现页错误（page fault），操作系统进行接管，页处理程序执行.

---

<br/>


### 页错误

几乎所有操作系统都在**软件中处理页错误**
> 为什么不用硬件处理页错误
> - 页错误导致的硬盘操作很慢，此时硬件相较于软件的速度提升可以不予考虑
> - 如果用硬件处理页错误，硬件需要了解交换空间，向硬盘发起IO操作，....，更复杂

操作系统通常采用 PTE 中本来存储 PFN 的位来 存储硬盘的地址，操作系统会从 PTE 中读取到地址，然后发送请求到硬盘，将页读取到内存中。

页错误处理流程如下
<center>
<img src="https://picture-in-md.oss-cn-guangzhou.aliyuncs.com/2023-03-22_154824.png" width="600" />
</center>

当 IO 在运行时，此时程序处与阻塞（blocked）状态，操作系统可以进行上下文切换运行其他可执行程序（CPU 和 IO 并行操作）。

---

<br/>


### 页交换

处理页错误需要把一个页放入内存中，如果内存已满或将要满，此时需要选择某些页被替换，也就是页交换策略（page-replacement policy）。

实际上，操作系统会主动预留一小部分空闲内存——系统发现空闲页数量少于**低水位线**LW（Low Watermark）时，后台负责释放内存的线程会开始运行，直到有**高水位线** HW（High Watermark）个空闲页。

为了优化页交换时的性能，许多系统会把多个要写入的页聚集或分组，然后同时写入到内存空间。

---

<br/>


<br/>



## 超越物理内存：策略

### 缓存管理

由于内存只包含系统所有页的子集，所以可以把内存视为虚拟内存页的缓存，在进行缓存选择替换策略时，目标是让缓存命中尽量多。

程序平均内存访问时间 $AMAT=(P_{hit}*T_M)+(P_{miss}*T_D)$

在现代操作系统中，硬盘访问的成本非常高，即使小概率的未命中也会拉低程序总体 $AMAT$ 。

---

<br/>


### 最优替换策略

最优替换策略：替换内存中在最远将来才会访问到的页；该策略可以达到总体未命中数量最少。

由于未来的访问是无法清楚知道的，所以该最优替换策略很难实现，但是可以作为比较者和其他策略进行比较（对比可以得出策略的改进空间，以及有多接近完美）：
- 冷启动未命中（cold-start miss）或者强制未命中（compulsory miss）是指刚开始页还没加载到内存导致的未命中
- 容量未命中：由于缓存容量不足，将一个项目踢出以容纳一个新的项目
- 冲突未命中：只会出现在硬件中，因为硬件缓存对于项的放置位置是有限制的，也就是集合关联性

---


<br/>


### 简单策略

FIFO无法确定页的重要性，命中率低
> Belady's anomaly
> Belady（最优策略提出者）等人 发现了一个现象：当缓存增大时（但不至于把所有页都容纳），FIFO 策略的命中率反而降低了。


随机策略实现起来很简单，可以规避一些极端情况，但是同样不够智能，命中率是个随机的，取决运气。

---

<br/>


### 利用历史数据：LRU
一个可以使用的历史信息是频率
既一个频繁被使用的页更有价值，为了实现这个策略，需要在每次页访问时，将该页一点弄给列表最前面（表示频繁使用那一侧），系统需要每次对内存的引用做一些记录工作，这些记录反而有可能影响性能。

更常用的属性时访问的近期性。这里利用了局部性原理（如果程序，如顺序执行的不存在局部性，那么 LRU 命中率将和 FIFO、随机差不多）。

可以利用硬件支持，在每个页访问时更新内存中的时间字段，但是随着系统中页数量的增大时，扫描精确找到最近不常访问的页 时间代价太高。

---

<br/>



### 近似LRU
由于扫描精确找到最旧的页开销过大，现代系统普遍采用近似LRU，不一定需要精确找到绝对最旧的页，只需找到差不多旧的页，具体实现方法如下：
- 在硬件中增加一个使用位（use bit）,当每页被引用时，使用位设置为1
- 时钟算法：所有页都存放在一个循环列表中，时钟指针 $p$ 开始时指向某个特定的项，当要进行页面替换时，检测 $p$ 指向的项的使用位是否为1，如果为1，就设置为0，然后指针移向下一个项，直到找到一个使用位为 0的项。

<center>
<img src="https://picture-in-md.oss-cn-guangzhou.aliyuncs.com/2023-03-22_164150.png" width="550" />
</center>



在有局部性的程序中，时钟算法不如完美LRU，但由于其他没有考虑历史访问的算法

时钟算法的一个修改：增加脏位，记录页面是否被修改，在选择被替换的页时优先考虑干净的页；脏页需要写回硬盘，消耗高，而干净的页不需要写回硬盘。

---

<br/>


### 其他虚拟内存策略

预取（prefetching）：操作系统按需取页，可以预测页面是否会被载入，从而提前载入。

聚集写入、分组写入：对于要写入硬盘的页面，许多系统会在内存中收集一些待完成写入，然后一起写入硬盘。
> 硬盘驱动器的性质：执行单次大的写操作，比许多小的写操作更高效


**抖动（thrashing）**：由于内存被超额请求，系统不断进行换页
- 一些早期的系统有一组复杂的机制：系统可以不运行部分进程，从而让运行的进程取得进展，这种方法称为准入控制
- 目前一些系统采用更严格的方法：某些版本Linux会运行“out-of-memory killer”程序来杀死一个内存密集型进程

---

<br/>


<br/>


## VAX/VMS 虚拟内存系统

本章以 VAX 操作系统为例，研究虚拟内存管理系统。

### 内存管理

VAX-11采用分页和分段结合的方式，提供32为地址空间，23为VPN中前2位用于区分分页所在的段
地址空间上半部分为系统空间，下半部分称为进程空间，进程空间有分为两个部分：P0（代码、堆）、P1（栈）

<center>
<img src="https://picture-in-md.oss-cn-guangzhou.aliyuncs.com/2024-08-09_172558.png" width="350" />
</center>




由于 VAX-11的页很小，为了减少页表数量：VAX-11为进程每个区域（P0、P1）单独提供一个页表，未使用的空间不需要页表空间，基址和界限寄存器分别保存的是页表的开始地址和大小；用户页表放置在内核虚拟内存中。

代码段地址不会从0开始，地址空间第一个页被标记为无效。

VAX-11内核映射到每个进程的地址空间中，在进行上下文切换时，不需要改变系统空间的基址和界限寄存器，这种构造使得内核就几乎项引用程序库一样（进程在进行系统调用时无须切换地址空间）。


---

<br/>


### 页替换

VAX-11采用分段的 FIFO 替换策略

每个进程都有一个可以保存在内存中的最大页数——驻留集大小RSS（Resident Set Size），每个页保存在FIFO列表中，当一个进程超过RSS时，先入的页会被驱逐；为了提高FIFO的性能，引入两个二次机会列表（second-chance list）：

- 干净页列表：（无须写回硬盘）空间可供别的进程使用
- 脏页列表：将大批量脏页聚合一起写入硬盘（从而变干净）

---

<br/>


### 其他VM技巧
VMS 有两成为标准的技巧——按需置零、写时复制，这两个技巧使用了惰性（lazy）优化。


**按需置零**

当一个页被添加到进程地址空间时，操作系统进行的工作：在页表中添加一个部分访问的条目；只有当进程访问该页，向操作系统发送陷阱，操作系统才进行寻找物理页，然后将页置零

<br/>


**写时复制**

当操作系统需要把一个页从一个地址空间复制到另一个地址空间时，只是将其映射到另一个地址空间，并且在两个地址空间中都标记其为只读；如果其中一个地址空间尝试写入页面，就会陷入操作系统，（惰性地）分配一个新的页，填充数据
> fork 系统调用使用写时复制：由于复制整个地址空间的副本很慢，而且大部分 fork（）操作复制的地址空间会被 ecec 立即覆盖。


---

<br/>


<br/>


<br/>



# 主题二 并发

## 并发：介绍

多线程（multi-threaded）程序有多个执行点，每个线程类似于独立的进程，但是线程之间可以 **共享地址空间**，**但是栈不会共享**，每个线程有自己的栈（结果就是多线程进程地址空间有多个栈）。

<center>
<img src="https://picture-in-md.oss-cn-guangzhou.aliyuncs.com/2023-03-23_110421.png" width="600" />
</center>

每个线程有自己的一组用于计算的寄存器，当进行线程切换时，需要进行上下文切换，但无需改变地址空间（不用切换当前页表）。

一个简单创建多线程实例如下：

<center>
<img src="https://picture-in-md.oss-cn-guangzhou.aliyuncs.com/2023-03-23_110628.png" width="700" />
</center>

- pthread_create 创建线程，线程创建后何时执行取决于操作系统的调度
- pthread_join 用于阻塞主进程，等待子进程执行完毕后，再继续执行

<br/>

**线程共享数据带来的问题**

由于线程之间可以共享堆中的数据，当多个线程同时操纵堆中同一个数据导致意想不到的问题，一个例子如下：

<center>
<img src="https://picture-in-md.oss-cn-guangzhou.aliyuncs.com/2023-03-23_111318.png" width="500" />
</center>

两个线程同时对 counter 进行操作，在进行进程的上下文切换时候，可能会有以下情况：在执行 add 之后还没来得及将值写回内存就进行上下文切换了。

<center>
<img src="https://picture-in-md.oss-cn-guangzhou.aliyuncs.com/2023-03-23_111835.png" width="600" />
</center>



**竞态条件（race condition）**：结果取决于代码的时间执行。

由于执行以上代码的多个线程可能导致竞争状态，此段代码被称为**临界区（critical section）**。

<br/>

**原子性**

为了解决以上问题，一个途径就是拥有强大的指令，单步就能完成需要做的事情，避免不合时宜的中断；此时硬件保证它以原子方式（atomically）方式执行（要么不执行，要么执行完成）。

实际上不可能存在这样的指令，但是可以要求硬件提供一些有用指令，帮助构建一个通用的集合，即**同步原语（synchornization primitive）**。

除了以上谈到的共享变量的交互，另一种常见的交互是一个线程在继续之前必须等待另一个线程完成某些操作（例如，进程执行 IO 带来的睡眠）。

---

<br/>


<br/>


## 插叙：线程 API

### 线程创建与完成

在 POSIX 中创建线程的方式如下：
> POSIX 是**可移植操作系统接口**（Portable Operating System Interface of UNIX，缩写为 POSIX），它是一个 IEEE 1003.1标准，其定义了应用程序（以及命令行 Shell 和实用程序接口）和 UNIX 操作系统之间的语言接口。当 UNIX 程序从一个 UNIX 平台移植到另一个平台时，遵守该标准可以确保其兼容性。

<center>
<img src="https://picture-in-md.oss-cn-guangzhou.aliyuncs.com/2023-03-23_133701.png" width="650" />
</center>

- pthread_t*：指向 pthread_t 结构体指针，利用该结构体与线程交互
- 第二个参数指定线程的属性
- 第三个参数为函数指针，即线程要执行的函数
- 第四个参数 arg 为传递给线程开始执行的函数的参数

<br/>


函数 pthread_join 用于等待线程完成，具有两个参数：
- pthread_t 用于指定要等待的线程
- 第二个参数是一个指针，指向要 得到线程执行的函数的返回值 的变量

---

<br/>


### 锁 lock

除了线程创建和等待之外，POSIX 线程库提供的最有用的函数集是——通过锁来提供互斥进入临界区的函数

<center>
<img src="https://picture-in-md.oss-cn-guangzhou.aliyuncs.com/2023-03-23_135130.png" width="650" />
</center>

<br/>

对于 POSIX 线程，初始化锁的方式：
- 使用 PTHREAD_MUTEX_INIIALIZER，将锁设置为默认值，从而使锁可用

<center>
<img src="https://picture-in-md.oss-cn-guangzhou.aliyuncs.com/2023-03-23_135607.png" width="500" />
</center>

- 动态方法：调用 pthread_mutex_init（），通常使用此方式；用完锁之后还需要调用 pthread_mutex_destroy（）

<center>
<img src="https://picture-in-md.oss-cn-guangzhou.aliyuncs.com/2023-03-23_135852.png" width="500" />
</center>

以上获取锁和释放锁的调用有可能会失败，需要额外进行检查（调用返回值为 0 代表调用失败）。


<br/>


以下两个调用用于获取锁：

<center>
<img src="https://picture-in-md.oss-cn-guangzhou.aliyuncs.com/2023-03-23_141212.png" width="600" />
</center>

- trylock：如果锁被占用则失败
- timed 版本：会在超时约定时间 或者 取得锁后返回

这种函数会在之后提到的死锁缺陷的预防中提到。

---

<br/>

### 条件变量

线程之间需要某种信号进行协调操作时，可以用到条件变量：

<center>
<img src="https://picture-in-md.oss-cn-guangzhou.aliyuncs.com/2023-03-23_141552.png" width="650" />
</center>

- pthread_cond_wait 调用使线程进入休眠状态，直到其他线程发出条件信号；等待调用除了使得线程睡眠，还让**线程睡眠时释放锁**，在被唤醒之后又会重新获得锁。
- signal 调用用于发信号，唤醒线程。

<br/>

两个调用使用实例如下：

<center>
<img src="https://picture-in-md.oss-cn-guangzhou.aliyuncs.com/2023-03-23_142210.png" width="700" />
</center>

---


<br/>


<br/>



## 锁

### 锁的基本思想

锁是一个变量，保存了锁在某一时刻的的状态：
- 可用（没有线程持有锁）
- 不可用（处于临界区）

POSIX 库将锁称为**互斥量（mutex）**，用来**提供线程之间的互斥**（多个线程使用同一个锁来实现对于临界资源的互斥操作）；
- 不同临界区使用同一个大锁（粗粒度的锁策略）
- 使用不同的锁保护不同的数据结构（细粒度的锁策略）


---

<br/>


### 锁的实现方法

**锁的评价标准**
- 提供互斥：最根本的指标
- 公平性：每一个竞争线程是否有公平机会抢到锁
- 性能：评价使用锁之后的时间开销

<br/>


**控制中断**

最早的提供互斥解决方案之一，在临界区 关中断，该方案为单处理器系统开发，优点是简单。

缺点很多：

- 允许所有线程执行特权操作（有恶意程序的风险）
- 只适用于单处理器系统
- 关闭中断导致中断丢失问题（例如，CPU可能会错过来自IO的中断请求，导致数据丢失）
- 效率低

只在很有限的情况下使用关闭中断——操作系统本身采用

<center>
<img src="https://picture-in-md.oss-cn-guangzhou.aliyuncs.com/2023-03-29_154702.png" width="500" />
</center>


<br/>

**没有硬件支持的测试并设置指令 test-and-set**

test-and-set instruction 是最简单的硬件支持指令，也称为原子交换（atomic exchange）；

核心思想是，用变量标记锁是否被占用，在调用 lock 时，进行测试和设置操作，直到锁可用。在 unlock 时，将变量复位。

<center>
<img src="https://picture-in-md.oss-cn-guangzhou.aliyuncs.com/2023-03-29_154737.png" width="550" />
</center>



在没有硬件支持的前提下，这种方法存在正确性和效率问题，当一个线程在调用 lock ，在跳出 test 循环时，恰好进行线程切换，有可能有两个线程同时获得锁，如下：

<center>
<img src="https://picture-in-md.oss-cn-guangzhou.aliyuncs.com/2023-03-29_155041.png" width="600" />
</center>


性能问题，由于在等待获得锁时，采用自旋等待（spin-waiting）技术，浪费了 CPU 资源.

<br/>

**有硬件支持的测试并设置指令 test-and-set**

由于之前的 test-and-set instruction 没有硬件支持，即 test 和 set 是两个指令，出现了正确性问题，一些操作系统提供了 test-and-set instruction 的原子指令（即 test 和 set 一起执行，合并为一个原子操作），在 SPARC 上被称为 ldstub，在 X86上被称为 xchg 原子交换（atomic exchange），该指令执行的操作如下：

<center>
<img src="https://picture-in-md.oss-cn-guangzhou.aliyuncs.com/2023-03-29_155914.png" width="600" />
</center>

利用该指令实现锁的过程如下：

<center>
<img src="https://picture-in-md.oss-cn-guangzhou.aliyuncs.com/2023-03-29_160049.png" width="600" />
</center>

- 实现的锁是正确的锁，实现了互斥
- 公平性：**自旋锁不提供任何公平性**，自旋的线程在竞态条件可能永远自旋
- 性能：在单CPU情况下，一个没有锁的线程会进行自旋拜拜浪费一个CPU周期；当对于多CPU系统来说，性能不错


<br/>


**比较并交换指令 compare-and-exchange**

比较并交换指令实现出来的锁和 test-and-set 实现的锁基本一样，只是细节有所不同，该指令执行的操作如下：

<center>
<img src="https://picture-in-md.oss-cn-guangzhou.aliyuncs.com/2023-03-29_160805.png" width="600" />
</center>

可以看出和 test-and-set 基本一样，支持在 set 之前增加了比较操作，set 过程变为 exchange 操作。

但是 compare-and-exchange 比 test-and-set 更灵活。


<br/>

**链接加载 和 条件存储指令**

一些平台提供了临界区的一对指令，在 MIPS 架构中，链接加载和条件存储指令配合使用实现其他并发结构，Alpha、PowerPC 和 ARM 都提供类似的指令。

> MIPS 是一个指令集架构，它是一种广泛使用的精简指令集计算机（RISC）架构。MIPS 架构以其高效和优化的特点而闻名，具有高度的扩展性，设计简单，设计周期短，并且可以应用更多先进技术来开发更快的处理器。MIPS 架构最早由斯坦福大学在 1981 年开发，其设计初衷是通过指令流水线化来增加 CPU 运算速度 。MIPS 架构的处理器广泛应用于嵌入式系统、工作站和计算机系统 。

<center>
<img src="https://picture-in-md.oss-cn-guangzhou.aliyuncs.com/2023-03-29_162204.png" width="600" />
</center>


链接的加载指令 和 典型加载指令类似，条件存储指令只有在上一次加载的地址 期间都没有更新才成功。

<center>
<img src="https://picture-in-md.oss-cn-guangzhou.aliyuncs.com/2023-03-29_162525.png" width="600" />
</center>

条件存储指令需要判断上一次加载的地址是否更新的原因在于，当线程在链接加载且跳出循环后，有可能进行线程切换，另一个线程可能会获取锁进入临界区，因此需要额外判断。

<br/>


**获取并增加 fetch-and-add**

fetch-and-add 指令执行的操作是，原子地返回特定地址的旧值，然后将该值加一，用其实现的 **ticket 锁**如下：

<center>
<img src="https://picture-in-md.oss-cn-guangzhou.aliyuncs.com/2023-03-29_163440.png" width="600" />
</center>


ticket **给每一个申请锁的线程分配一个 ticket**，然后在一个线程**调用 unlock 时**，让 turn+1，即**让 ticket 比该线程大一的线程获取锁**。实际上，就是按照线程申请锁定顺序，依次分配锁。

该方法保证了所有线程都能抢到锁。

<br/>


基于硬件的锁简单而且有效，但是仅依靠硬件需要自旋等待，在某些情况下，效率低下，所以需要操作系统的支持，以下讨论消除自旋的方法：

**简单方法：放弃 CPU**

当要进行自旋时，利用操作系统，让该线程放弃 CPU，让线程从运行状态变为就绪状态；虽然比自旋浪费时间片的方案效率高，但是成本依然很高，上下文切换成本高（尤其是切换给到的是同样等待锁可用的线程）。

**使用队列和休眠**

上一个方法存在偶然性，即进行上下文切换时，切换的线程不一定是拥有锁的线程。此外为了防止线程饿死的现象，必须显示加以控制——决定锁释放时，哪个线程能够拥有锁。

利用 Solaris 提供的支持，**park 调用让线程休眠，unpark 调用唤醒线程**，一种可能的实现方法如下：

> Solaris 是由 Sun Microsystems 公司研发的 UNIX 操作系统，后来随着 Sun 公司被 Oracle 收购，现在称为 Oracle Solaris。它是一个多用户多任务的操作系统，支持多种硬件平台，包括 SPARC 和 x86 架构。Solaris 操作系统以其高度的安全性、优化的性能、以及先进的虚拟化功能而著称。

<center>
<img src="https://picture-in-md.oss-cn-guangzhou.aliyuncs.com/2023-03-29_165129.png" width="550" />
</center>



guard 的意义在于，线程在获取或释放锁的过程中有可能被打断，需要用 guard 进行保护
在 unlock 时，调用 unpark 之前并没有将 flag 设置为一，因为线程被唤醒后，将会在 park 之后继续执行（类似函数调用），相当于直接把锁传递给被唤醒的线程。

**唤醒/等待竞争问题**：在线程 B 调用 lock 后，执行 m->guard=0之后进行上下文切换，如果切换到拥有锁的线程 A，线程 A 执行 unpark 操作，但是由于此时线程 B 没有休眠，所以操作无效，但是切换会线程 B 之后，会继续执行 park 休眠操作，且此时将不会再有其他线程会唤醒线程B.

为了解决唤醒/等待竞争问题，**Solaris 提供了 separk**——线程 B 表明自己即将被 park，如果进行上下文切换，且另一个线程调用了 unpark，则线程 B 后续 park 调用直接返回而不是休眠。

<br/>

**Linux 的实现**

Linux 提供了 futex ，每个 futex 关联了一个特定的物理内存位置，有实现建立好的队列，futex 调用使用方法如下

- futex_wait（address，expected）：当 address 处的值等于 expted 就让线程休眠
- futex_wake（address）：唤醒队列中的一个线程

基于 Linux 的 futex 锁如下：

<center>
<img src="https://picture-in-md.oss-cn-guangzhou.aliyuncs.com/2023-03-29_171549.png" width="600" />
</center>



<br/>


**两阶段锁 two-phase lock**

Linux 采用一种古老的锁方案——两阶段锁（two-phase lock），此方案意识到**自旋可能很有作用，尤其是锁就快释放的场景**。

两阶段锁的思想是：第一阶段先自旋一段时间，如果第一阶段没有获得锁就进行第二阶段——休眠.

两阶段锁是结合了自旋和队列的一种方案，基于 Linux 的 futex 锁也是两阶段锁（一个 if 语句 相当于第一阶段 只自旋一次）。

---


<br/>


<br/>


## 基于锁的并发数据结构

本章主要介绍一些常用数据结构如何使用锁实现线程安全，同时保证高性能。

**并发计数器**

计数器是最简单的一种数据结构，并发计数器相当于在计数器的加、减和访问操作的临界区用锁保护起来，实现如下：

<center>
<img src="https://picture-in-md.oss-cn-guangzhou.aliyuncs.com/2023-03-30_091929.png" width="500" />
</center>



该计数器简单正确，在单线程中效率高，但是对于多线程程序效率差，因为所有线程都要共用一个计数器，拓展性差（线程越多，效率越低）。

<br/>


**可拓展的计数器**

懒惰计数器 **在每个 CPU 设置计数器，还设置一个全局计数器**，单个核心只会用该核心上的计数器，然后**局部值会定期转移给全局计数器**（当然在进行局部和全局计数器的更新操作时，都要用锁保护，不过每个计数器有独立的锁）。

局部转全局的频度，取决于阈值 $S$ ， $S$ 越小，懒惰计数器越趋近于非拓展的计数器， $S$ 越大，拓展性越强，但是精确度越低。

<center>
<img src="https://picture-in-md.oss-cn-guangzhou.aliyuncs.com/2023-03-30_092804.png" width="300" />
</center>

<center>
<img src="https://picture-in-md.oss-cn-guangzhou.aliyuncs.com/2023-03-30_092820.png" width="300" />
</center>


<br/>

**并发链表**

并发链表的简单实现是——在链表的插入、删除和查询操作一开始就调用锁；这种方法存在的问题是——当进行额外操作失败（如 malloc 失败）之前，必须释放锁，所以必须获取锁和释放锁只环绕真正的临界区，如下：

<center>
<img src="https://picture-in-md.oss-cn-guangzhou.aliyuncs.com/2023-03-30_093349.png" width="500" />
</center>

<br/>

**拓展的并发链表**

上面的并发的链表和计数器存在一样的问题，由于只有一个锁，多个线程访问该链表时，效率很低，拓展性不好；在增加链表并发的过程中有过一种 称为**手锁（hand-over-hand locking，或者锁耦合）**的技术——每个节点都有一个独立的锁，遍历链表时首先抢占下一个节点的锁，然后释放当前节点的锁。

但是每个节点获取锁释放锁的开销巨大，性能一般比单锁差；为了兼顾拓展性和锁操作的开销，可以采用杂合方案——在一部分节点增加锁。

更多并发不一定快，如果带来了大量的开销，那么这种高并发就没有什么意义。


<br/>

**并发队列**

队列在**多线程程序中广泛使用**，以下是简单实现（并不完善）

<center>
<img src="https://picture-in-md.oss-cn-guangzhou.aliyuncs.com/2023-03-30_095032.png" width="400" />
</center>

可以看到，采用了两个锁，分别复杂队头和队尾，可以使得入队和出队操作可以并发执行.

<br/>


**并发散列表**

并发散列表是广泛采用的数据结构，以下是用并发链表实现的一个例子，性能特别好，**每个散列桶是一个并发链表，拥有独立的锁**，因此散列表中含有多个锁，但是又不是像手锁一样每个节点都有。

并发散列表是 考虑了拓展性和 锁操作开销 的一个杂合方案的例子：

<center>
<img src="https://picture-in-md.oss-cn-guangzhou.aliyuncs.com/2023-03-30_095540.png" width="500" />
</center>


---

<br/>


<br/>


## 条件变量

锁并不是并发程序设计所需的唯一原语，很多情况下，线程需要检查某一条件满足之后，才会继续运行。

一个简单的想法是，用一个共享的变量，这种方法需要自旋，会浪费 CPU 时间。

### 定义和使用条件变量

条件变量是一个显式队列，当某些执行条件不满足时，线程可以把自己加入队列，然后休眠等待条件满足。

条件变量需要定义和初始化，与 两个系统调用配合使用：
- wait 负责释放锁，并让调用的线程休眠（原子地），当线程被唤醒后，重新获得锁并返回给调用者
- signal 负责唤醒线程

一个使用条件变量的例子如下，作用是父线程等待子线程执行完后继续执行：

<center>
<img src="https://picture-in-md.oss-cn-guangzhou.aliyuncs.com/2023-03-30_135027.png" width="550" />
</center>


状态变量的必要性：使用条件变量时，尝尝配合一些状态变量使用，在本例中，状态变量 done 用于标记子线程是否已经执行完，以规避特殊情况——子线程线先于父线程执行，子线程执行 signal 唤醒之后，父线程之后再 wait 进入休眠，此时父线程将一直休眠下去。

while 循环代替 if 语句：此处使用 while 不是必要的，但是有多个子线程时，while 循环就很有必要。

**条件变量总是与锁配合**：以上例子在使用条件变量时配合锁来使用（其实 wait 也强制要求使用锁），使用锁是为了避免竞态条件——当父线程进行完条件判断，即将进入 wait 休眠时，系统上下文切换到子线程，子线程执行 signal，之后切换回父线程执行休眠，这样父线程将会一直休眠下去（可以这样理解，如果没有锁，状态变量的设置将没有意义）。

---

<br/>

### 生产者/消费者问题

生产者/消费者问题（producer/consumer）也称为有界缓冲区问题，有界缓冲区是共享资源，需要同步机制访问——条件变量。

一个简单的例子，缓冲区只有一个空间，相关操作如下：

<center>
<img src="https://picture-in-md.oss-cn-guangzhou.aliyuncs.com/2023-04-06_165009.png" width="600" />
</center>



以下是利用条件变量给出的一个解决方案：

<center>
<img src="https://picture-in-md.oss-cn-guangzhou.aliyuncs.com/2023-04-06_165133.png" width="600" />
</center>



当只有一个生产者和一个消费者时，以上方案可以正常运行，但是当有多个消费者时会出现问题：

- **Mesa 语义问题**：当生产者填满缓冲区，唤醒睡眠的消费者1之后，消费者1没有立刻执行，此时出现了新的消费者2，将缓冲区清空，当消费者1执行时，会触发断言，程序终止。根本原因在于线程在被唤醒之后没有进来状态的判断，所以可以**使用 while 语句替代 if 语句**。

> - Mesa语义：被唤醒的线程不会立即执行，执行的时候，情况可能和刚唤醒的情况有所不同。几乎所有系统都采用了Mesa语义
> - Hoare语义：保证被唤醒的线程立即执行

- **唤醒错误的线程的问题**：假如生产者和消费者1都在休眠等待信号唤醒，此时消费者2在运行，其清空缓冲区之后，会发出信号唤醒睡眠线程，问题在于可能会唤醒一个错误的线程（pthread_cond_signal 只会唤醒队列中其中一个线程），如果唤醒的是消费者1，消费者1发现缓冲区为空会继续休眠，而消费者2在发出信号之后页进行了休眠，此时所有的线程都进入休眠且一直休眠下去。**根本问题在于，生产者和消费者使用同一个条件变量，使得唤醒的对象没有指向性**，可以使用两个条件变量。

修改之后的方案如下：

<center>
<img src="https://picture-in-md.oss-cn-guangzhou.aliyuncs.com/2023-04-06_170646.png" width="400" />
</center>

<center>
<img src="https://picture-in-md.oss-cn-guangzhou.aliyuncs.com/2023-04-06_170701.png" width="500" />
</center>

---

<br/>


### 覆盖条件

以下为一个简单的多线程内存分配库的例子：

<center>
<img src="https://picture-in-md.oss-cn-guangzhou.aliyuncs.com/2023-04-06_171503.png" width="500" />
</center>



显然以上方案存在和有界缓冲区例子一样的问题，即可能唤醒错误的线程，除了使用两个条件变量以外，还有另外一种解决方案——覆盖条件

覆盖条件是用 pthread_cond_broadcast（）代替 pthread_cond_signal（），这样可**以唤醒所有等待该信号的线程**。

这种方法的缺点是不必要的唤醒了其他本不应该被唤醒的线程。


---

<br/>


<br/>


## 信号量

### 信号量的定义

**锁是互斥机制**，**条件变量用于线程之间的协作**，而**信号量是一种同步机制**。

信号量是有一个整数的对象，被用来对资源的数量进行计数，以便控制对资源的访问，可以用两个函数进行操作：

- sem_wait：信号量的值大于等于1，则立即返回，否则进入队列等待被唤醒；调用该操作之后信号量的值会减一
- sem_post：直接增加信号量的值，如果有等待线程就唤醒其中一个

可以看出**信号量的值为负数时，其绝对值大小就是等待线程的数量**。

---

<br/>

### 信号量的使用

**二值信号量**

相当于用信号量作为锁，信号量初始化时初值设置为1，使用方法如下：

<center>
<img src="https://picture-in-md.oss-cn-guangzhou.aliyuncs.com/2023-04-06_195351.png" width="600" />
</center>

sem_init 的第二个参数设置为0，表示信号量是在同一个进程的多个线程共享。因为锁只有两个状态（被持有或没被持有），这种用法被称为二值信号量（binary semaphore）

<br/>

**信号量作为条件变量**

回到讨论开始条件变量的那个例子——父进程等待子进程执行完成之后再继续执行。

这里用信号量实现，只需要将信号量初始值设置为 0，在父进程中调用 sem_wait，在子进程最后一条语句调用 sem_post，对于以下两种情况进行讨论可行性：

- 父线程先调用sem_wait：此时父线程进入休眠，等待子进程唤醒
- 子线程先调用sem_post：子线程线调用意味着子进程先执行完，此时父线程不休眠也达到了目的

---

<br/>


### 生产者/消费者问题

用信号量解决生产者/消费者问题，一个尝试如下：

<center>
<img src="https://picture-in-md.oss-cn-guangzhou.aliyuncs.com/2023-04-06_200422.png" width="600" />
</center>

这种方案对于单个生产者和单个消费者来说是符合预期的，但是对于多个生产者和消费者来说会产生竞态条件：当两个生产者几乎同时调用 put 时，先调用的线程填入了数据，在更新计数器之前发生了中断，另一个线程会在同一个位置写数据，把之前的数据覆盖掉，根本原因是缓冲区增减元素是临界区，需要互斥保护。

一个依然错误的改进方案：

<center>
<img src="https://picture-in-md.oss-cn-guangzhou.aliyuncs.com/2023-04-06_201201.png" width="600" />
</center>


从上面可以看出，加了锁导致了新的问题：当消费者先运行，消费者进入休眠，此时消费者拥有锁，新的生产者无法获得锁从而填充数据从而唤醒消费者，二者陷入了一个循环等待

解决问题——只需减少锁的作用域，**把互斥量的获取和释放紧挨临界区**。

---

<br/>

### 读者—写者锁

不同数据结构访问可能需要不同类型的锁，例如，一个并发链表，查找操作没有改变链表状态，因此可以并发执行多个查找操作，而插入操作不能。

以下为一个简单的 reader-writer lock 的实现：

<center>
<img src="https://picture-in-md.oss-cn-guangzhou.aliyuncs.com/2023-04-06_203452.png" width="600" />
</center>



第一个读者会得到 wirterlock，最后一个读者会释放 writerlock，这样可以保证多个读操作并发进行，且读时不会有写操作，写操作之后等所有读操作完成之后才能获得锁之后进行。

这个方案存在公平性问题，读者很容易饿死写者。

---

<br/>


### 哲学家就餐问题

<center>
<img src="https://picture-in-md.oss-cn-guangzhou.aliyuncs.com/2023-04-06_203942.png" width="350" />
</center>



如果所有哲学家都是先那左手边或右手边的叉子，很可能造成死锁问题，如下图：

<center>
<img src="https://picture-in-md.oss-cn-guangzhou.aliyuncs.com/2023-04-06_203942%20(1).png" width="350" />
</center>



最简单的解决方案：改变某个或某些哲学家的取餐叉顺序。

---

<br/>


<br/>


## 常见并发问题

### 非死锁缺陷

非死锁问题占了并发问题的大部分，其中主要包含违反原子性和错误顺序。

**违反原子性（atomicity violation）**

违反了多次内存访问中，可预期的可串行性，即代码本意是原子的，但是在执行过程中没有强制实现原子，以下为 MySQL 中出现的一个例子：

<center>
<img src="https://picture-in-md.oss-cn-guangzhou.aliyuncs.com/2023-04-07_100744.png" width="500" />
</center>



以上代码出现问题的原因在于没有给提供互斥，简单解决方法是给共享内存的访问加锁

<br/>

**违反顺序缺陷（order violation）**

两个内存访问的预期顺序被打破了，即 A 应该在 B 之前先执行，但是实际运行中并不是这个顺序，一个例子如下：

<center>
<img src="https://picture-in-md.oss-cn-guangzhou.aliyuncs.com/2023-04-07_101142.png" width="500" />
</center>

如果线程 1 没有首先执行，线程2可能会崩溃，简单解决方法是利用条件变量。

---

<br/>

### 死锁缺陷 deadlock
死锁是一种在许多复杂并发系统中出现的经典问题

<center>
<img src="https://picture-in-md.oss-cn-guangzhou.aliyuncs.com/2023-04-07_101712.png" width="500" />
</center>


**为什么会产生死锁？**

上图提到的死锁的例子很容易可以避免，只要线程 1 和线程2使用相同的抢锁顺序，但为什么还是会有死锁问题：

- 复杂的依赖关系：在大型代码库中，组件之间有着复杂的依赖关系，很难全部采用相同的抢锁顺序
- 封装：封装隐藏了实现细节，正是如此某些看起来没有关系的接口可能会导致死锁

**产生死锁的条件**
死锁的产生需要同时满足以下四个条件：

- 互斥：资源需要进行互斥的访问
- 持有并等待：线程持有资源，同时又在等待其他资源
- 非抢占：线程已经获得的资源，不能被别的线程抢占
- 循环等待：线程之间存在环路关系

**死锁的预防**
根据死锁产生的条件，某个策略设法阻止其中一个条件，便可以预防死锁

- **循环等待**

最实用的预防技术，在获取锁时提供一个全序（total ordering），即所有线程获取锁的顺序相同；更复杂的系统中，有很多锁，偏序（partial ordering）是一种有用的方法
> 通过锁的地址来强制锁的顺序
> 假设有一个函数do_something( mutex* m1 , mutex* m2 )，如果两个调用该函数的线程，传入的参数顺序相反，就可能造成死锁；为了避免这种特殊的问题，可以根据锁的地址作为获取锁的顺序，这样不论传入的参数顺序如何，函数都会用固定的顺序加锁

- **持有并等待**

可以通过原子地抢锁来避免，即一个线程会原子地抢占所有需要的锁，结果就是线程要么没有持有锁，要么持有所有锁，例子如下：
<div align="center"> <img src="https://cdn.nlark.com/yuque/0/2023/png/29674612/1680835164212-0ec32202-f4d4-49cf-81d6-54729020741e.png#averageHue=%23fdfcfc&clientId=u6b2c48eb-74f2-4&from=ui&height=135&id=u5c8248ac&originHeight=148&originWidth=660&originalType=binary&ratio=1.3499999046325684&rotation=0&showTitle=false&size=7716&status=done&style=none&taskId=u92615116-a580-4fb0-9422-b61266dfc01&title=&width=600" width="600" /> </div>


这种方案需要准确知道所有要抢占的锁，不适用于封装

- **非抢占**

在调用unlock之前，锁被认为是占有的，这是可能会导致等待一个锁时同时持有一个锁，很多线程库提供了更灵活的接口来避免这种情况，具体来说trylock（）函数会尝试获得锁，例子如下：
<div align="center"> <img src="https://cdn.nlark.com/yuque/0/2023/png/29674612/1680835601315-b869f9f6-38fb-41fa-b395-c927e67f863b.png#averageHue=%23fdfdfc&clientId=u6b2c48eb-74f2-4&from=ui&height=145&id=u6139df44&originHeight=173&originWidth=716&originalType=binary&ratio=1.3499999046325684&rotation=0&showTitle=false&size=11968&status=done&style=none&taskId=uc0b3f485-e750-464b-a931-797a7d2b089&title=&width=600" width="600" /> </div>


这种方式，在获取不到所有所需的锁时，不会一直持有锁，而是放弃所有已经获得锁，重新阐释获取，这种方式可能会导致其他问题：
第一个问题：活锁，当两个线程同时开始获取锁，但是获取锁的顺序相反，两个线程可能会一直重复获取锁的工作，代码一直没有进展，所以称为活锁，解决方案——在循环结束的时候随机等待一个时间，之后再重复动作，降低线程之间的重复干扰
第二个问题：封装，如果一个锁是封装在函数内部的，跳转回开头处的动作很难实现

- **互斥**

最后的预防方案是完全避免互斥，同时利用强大的硬件指令构造处不需锁的数据结构来解决临界区
以下是利用compare-and-swap指令实现的一个例子
<div align="center"> <img src="https://cdn.nlark.com/yuque/0/2023/png/29674612/1680836229978-f3cc9a6b-d514-4531-bcf8-b52463443e75.png#averageHue=%23fcfbfb&clientId=u6b2c48eb-74f2-4&from=ui&height=116&id=ucf2491db&originHeight=142&originWidth=732&originalType=binary&ratio=1.3499999046325684&rotation=0&showTitle=false&size=6975&status=done&style=none&taskId=u848198d9-8dc8-4ba2-86d9-2c6cc5b500d&title=&width=600" width="600" /> </div>



**通过调度避免死锁**
某些场景更适合死锁避免，需要了解全局的信息，例如已经线程对于锁的需求
<div align="center"> <img src="https://cdn.nlark.com/yuque/0/2023/png/29674612/1680836359823-be52fdd9-06fc-4a4f-8c31-3a23d9c33bc1.png#averageHue=%23edecec&clientId=u6b2c48eb-74f2-4&from=ui&height=114&id=u6edcd7ad&originHeight=159&originWidth=980&originalType=binary&ratio=1.3499999046325684&rotation=0&showTitle=false&size=9674&status=done&style=none&taskId=u3049b557-7a43-416b-bca0-536928e46f2&title=&width=700" width="700" /> </div>


此时调度程序不让需要一样锁的线程同时运行，就可以避免死锁，如下
<div align="center"> <img src="https://cdn.nlark.com/yuque/0/2023/png/29674612/1680836441852-1a79f38d-f1b3-4bba-8f5d-76f0f58309ff.png#averageHue=%23d6d6d6&clientId=u6b2c48eb-74f2-4&from=ui&height=65&id=u48f46b5e&originHeight=78&originWidth=481&originalType=binary&ratio=1.3499999046325684&rotation=0&showTitle=false&size=2105&status=done&style=none&taskId=ube3d872a-9d6c-4339-a830-c35ea9fd556&title=&width=400" width="400" /> </div>


但当大部分线程都需要同样的锁时，此时这种调度策略就不能让线程并发执行，限制了并发，付出了性能代价，并不是广泛采用的通用方案

**恢复和检查**
最后一种常用的策略是允许死锁的偶尔发生，检查到死锁时在采取行动（适用于死锁发生率低的场景）


## 33章 基于事件的并发
并发并不一定只能由线程来完成，一些基于GUI的应用程序，或者某些类型的网络服务器常使用基于事件的并发。
基于事件的并发针对两方面的问题：

- 多线程应用中，正确处理并发很多难度。
- 开发者无法控制多线程在某一时刻的调度。
### 基本思想：事件循环
等待事件发生，当事件发生后，检查事件类型，然后进行响应。
以下为基于事件的服务器，这类应用都是基于事件循环（event loop）：
<div align="center"> <img src="https://cdn.nlark.com/yuque/0/2023/png/29674612/1681367893685-c053c558-1c6d-44b4-ae88-eafdbebd2099.png#averageHue=%23fdfdfc&clientId=u8ad993c4-2e26-4&from=ui&height=113&id=u15b2c9af&originHeight=200&originWidth=706&originalType=binary&ratio=1.5&rotation=0&showTitle=false&size=6325&status=done&style=none&taskId=u6f7dfe0b-fa88-465b-82b7-fcd6831bc87&title=&width=400" width="400" /> </div>


处理事件的代码叫做事件处理程序（event handler），处理程序在处理一个事件时，是系统中唯一发生的活动。调度就是决定接下来处理哪个事件，这种对调度的显式控制，是基于事件方法的一个重要优点。
### 事件API：`select`
为了接收事件的问题，大多数操作系统提供了`select`或`poll`系统调用。用于检查是否有任何应该关注的进入I/O。
<div align="center"> <img src="https://cdn.nlark.com/yuque/0/2023/png/29674612/1681368635054-785cee91-0ff9-4224-a2c9-4524a25c90b6.png#averageHue=%23fbfaf9&clientId=u8ad993c4-2e26-4&from=ui&height=136&id=u65db29c5&originHeight=240&originWidth=1055&originalType=binary&ratio=1.5&rotation=0&showTitle=false&size=40726&status=done&style=none&taskId=ub0ce9f69-cd17-4951-bc7f-3fc22cd24e6&title=&width=600" width="600" /> </div>


`select`用请求操作准备好的文件描述符组成的子集替换给定的文件描述符结合，返回集合中就绪描述符的总数。
### 阻塞系统调用
如果某个事件要求发出可能会阻塞的系统调用，比如IO请求，可能需要很长时间才能提供服务。基于事件的方法，没有其他线程可以运行，当被阻塞时，会造成资源浪费，因此基于事件的系统必须遵守一条规则：不允许阻塞调用。

许多现代操作系统引入了新的方法发出IO请求，称为异步I/O。这些接口能够使程序在发出IO请求之后，在IO完成前就把控制权返回给调用者，另外还有用于应用确定IO是否完成的接口。
在macOS X上，提供了`aio_error()`调用，检查IO是否完成，程序可以通过调用该调用来周期性轮询系统，以确定IO是否完成。

以上方法对于有很多IO请求的情况，需要经常进行查询，效率很低。一些系统提供了基于中断的方法，使用UNIX的信号（signal）在异步IO完成时通知程序。
> UNIX信号
> 将信号传递给程序，程序停止当前工作，开始运行信号处理程序，完成之后，该进程恢复先前行为。

### 状态管理
基于事件的方法会比基于线程的方法代码更复杂，当事件处理程序发出异步IO时，必须打包一些程序状态，以便于之后的事件处理程序，在IO完成后进行处理。这就是手工栈管理（manual stack management），是基于事件编程的基础。
使用了一种称为“延续（continuation）”的老编程结构。核心思想是：用某种数据结构来记录完成处理该事件的完整信息，当事件发生（IO完成），查找所需信息并处理事件。
### 小结
基于事件的方法除了上面两种问题，还有其他问题：

- 当系统利用多CPU时，需要锁。
- 不能很好和某些类型系统活动集成，例如，事件处理程序发生页错误是，将被阻塞。
- 随着时间推移，基于时间的代码很难管理。

基于事件的并发为应用程序本身提供了调度控制，代价是：复杂性以及和现代操作系统集成难度。



# 主题三 持久性
## 36章 I/O设备
### 36.1 标准协议
简化的标准设备接口包含3中寄存器：状态寄存器（设备当前状态）、命令寄存器（设备执行的任务）、数据寄存器。
与设备的典型交互方式为程序查询方式，协议包含以下几个部分：

- 轮询设备
- 发送数据到数据存储器
- 写入命令
- 轮询设备，是否执行完成命令

CPU主动参与了数据的传输，称之为编程的I/O（programmed I/O，PIO）。

### 36.2 程序中断方式
程序查询方式简单有效，但是轮询过程比较低效，特别是对于低性能IO设备。可以采用中断方式来改进，程序发送IO请求后继续执行其他工作，IO设备准备好后，抛出硬件中断。
中断并非总是最佳方案：

- 对于高性能设备或者传输数据量少但是比较频繁的设备，程序查询方式处理很快，如果使用中断，上下文切换代价不小，反而让效率变低。
- 网络场景。网络端接收到大量数据包，如果对于每个包进行一次中断，有可能导致活锁。

一个基于中断的优化是合并。设备在抛出中断之前往往等待一小段时间，在此期间的其他中断合并为一次中断抛出。

### 36.3 DMA方式
参考计算机组成原理笔记

### 36.4 设备交互方式
操作系统主要有两种和设备交互的方式：

- 特定的IO指令：适用于IO设备单独编址的机器。
- 内存映射IO：IO设备和内存一起编址，可将将IO当成内存的一部分，不需要引入新的特定指令。

### 36.5 设备驱动程序
每个设备都有非常具体的接口，需要为每种设备编写设备驱动程序，将所有与设备交互的细节封装在其中。以下为Linux的文件系统栈：
<div align="center"> <img src="https://cdn.nlark.com/yuque/0/2023/png/29674612/1681375530899-df51c173-0f0d-4d85-9ce6-d22c461cb7e1.png#averageHue=%23dbdbdb&clientId=u8ad993c4-2e26-4&from=ui&height=180&id=uf36f81c2&originHeight=400&originWidth=1332&originalType=binary&ratio=1.5&rotation=0&showTitle=false&size=19492&status=done&style=none&taskId=ub5d4dbee-0933-472b-8215-60599648c05&title=&width=600" width="600" /> </div>


封装的好处是上层的部分不需要清楚底层实现。不足的地方是，一个设备本身可以提供很多特殊功能，为了兼容大多数操作系统不得不提供一个通用的接口，使得自身的特殊功能无法使用。


## 37章 磁盘驱动器
### 37.1 接口
驱动器由大量扇区（512字节块）组成，每个扇区可以读取或写入。可以同时进行多扇区读写，但是驱动器制造商唯一保证的是单个512字节的写入是原子的。

### 37.2 简单的磁盘驱动器
相关术语：

- 磁道track
- 寻道seek
- 旋转延迟rotational delay

磁道偏斜：确保在跨越磁道边界时顺序读取也可以继续进行。原理是磁道的结尾和下个磁道的开头不会再同一条半径上面，给了磁头重新定位的时间，避免错过开头，而不得不等待多一个旋转延迟。
<div align="center"> <img src="https://cdn.nlark.com/yuque/0/2023/png/29674612/1681376379505-8c13ed05-4e22-4bc6-ad63-50c3951c37d9.png#averageHue=%23eeeeee&clientId=u8ad993c4-2e26-4&from=ui&height=279&id=ud1ba7e35&originHeight=521&originWidth=560&originalType=binary&ratio=1.5&rotation=0&showTitle=false&size=25090&status=done&style=none&taskId=u90d452e4-65d5-47f3-9bed-1817fe8ed3e&title=&width=300" width="300" /> </div>



### 37.3 磁盘调度
对于磁盘调度，可以预测磁盘请求需要花费的时间，因此可以优先服务花费时间最少的请求，在磁盘的调度中遵循最短任务优先SJF原则。
**最短寻道时间优先SSTF**
SSTF（Shortest-Seek-Time-First）是一种早期的磁盘调度方法，优先服务距离磁头近的磁道的请求，这种方法存在以下问题：

- 操作系统无法利用驱动器的几何结构，只能识别出一些列块。操作可以使用最近块优先NBF（Nearest-Block-First）调度达到类似效果。
- 饥饿问题，一些距离大部分请求的磁道远的请求会被忽略。

**电梯SCAN**
向电梯一样，从内道到外道扫描并进行服务，避免远距离请求饥饿。一种常见的变体循环C-SCAN，从内圈到外圈，再由外圈到内圈循环进行下去。

**最短定位时间优先SPTF**
SSTF又是并不够好，单单从磁道来判定不够全面，如下图：
<div align="center"> <img src="https://cdn.nlark.com/yuque/0/2023/png/29674612/1681383332888-901e21db-4561-4452-a5fc-2deb4d465585.png#averageHue=%23efefef&clientId=u8ad993c4-2e26-4&from=ui&height=300&id=u9fe72876&originHeight=509&originWidth=509&originalType=binary&ratio=1.5&rotation=0&showTitle=false&size=23262&status=done&style=none&taskId=u9d0e3913-abf0-4fef-b279-ab53c4d1cc4&title=&width=300" width="300" /> </div>


SSTF或者NBF会选择扇区16，但根据磁盘的旋转方向，选择扇区8更快。SPTF（Shortest Positioning Time First）在寻道时间和旋转延迟相当时 很有用，但是操作系统通常不清楚磁头位置，所以SPTF通常在驱动器内部执行。


## 38章 廉价冗余磁盘阵列RAID
### 38.1 RID介绍
RAID（Redundant Array of Inexpensive Disks）是一种将多个硬盘组合使用，以提高读写性能和可靠性的技术。
> RAID技术的主要用途包括：
> - 数据冗余：通过将多个硬盘中的数据复制到另一个硬盘或分布在多个硬盘上，RAID技术可以提供数据冗余，以防止数据丢失和硬盘故障。
> - 性能优化：通过在多个硬盘上分布数据或复制数据，RAID技术可以提高数据访问速度和输入/输出操作的吞吐量。
> - 热备份：RAID技术可以通过将一个或多个备用硬盘保持在线状态来实现快速恢复，以防止故障硬盘造成的数据丢失或停机。

使用场景主要是高可靠性和高性能存储的场合，如服务器数据存储、大型数据中心。

RAID技术为使用其的系统透明提供服务，对于主机而言就像是一个大的硬盘。
RAID内部包含硬盘、DRAM、微控制器。RAID是一个非常专业的计算机系统，专门运行用于操作RAID的软件。
当文件系统向RAID发出逻辑IO请求时，RAID内部计算要访问的硬盘（可能有多个），然后发出一个或多个物理IO请求。

**RAID评估**
从以下方面评估RAID设计，分析不同设RAID设计方法的优缺点：

- 容量：相对于物理硬盘容量，客户端实际能够使用的硬盘容量。
- 可靠性：运行出现多少硬盘故障。
- 性能：读写速度。

### 38.2 RAID 0级：条带化
该级别实际上不是RAID级别，因为没有冗余，但是作为RAID性能和容量的上限。
简单的条带化如下：
<div align="center"> <img src="https://cdn.nlark.com/yuque/0/2023/png/29674612/1681437562449-5f919c1d-6e79-48b2-b279-c6ae53b5e0f1.png#averageHue=%23efeeee&clientId=u71374f12-77a8-4&from=ui&height=170&id=u34017a88&originHeight=238&originWidth=982&originalType=binary&ratio=1.5&rotation=0&showTitle=false&size=13670&status=done&style=none&taskId=ub2b3cd03-fc35-4b30-a49d-ff3bd442bfd&title=&width=700" width="700" /> </div>


以轮转方式将磁盘阵列的块分布到磁盘上，对于连续块请求获得最大的并行性。也可以使用较大的块进行条带化，如下：
<div align="center"> <img src="https://cdn.nlark.com/yuque/0/2023/png/29674612/1681437754373-0f0d09dd-5635-485d-9a13-cee20ee3781c.png#averageHue=%23edecec&clientId=u71374f12-77a8-4&from=ui&height=166&id=ud6cc722e&originHeight=229&originWidth=965&originalType=binary&ratio=1.5&rotation=0&showTitle=false&size=19927&status=done&style=none&taskId=u3dce74c0-78ef-4545-93d0-e02bf637fec&title=&width=700" width="700" /> </div>


块的大小设计考虑：

- 块太大：减少并行性。
- 块太小：将跨越许多磁盘进行条带化，磁盘的定位时间由定位时间最大的那个磁盘决定，可能导致定位时间增加。

大多数阵列使用较大的大块大小，例如64KB。

**RAID-0分析**

- 性能：对于单请求延迟，性能和单个磁盘一样。对于稳定吞吐量，设当个磁盘的顺序读写带宽为$S$，随机读写带宽为$R$，RAID-0中有$N$个磁盘，则顺序读写带宽为$NS$，随机读写带宽为$NR$。
- 容量：充分利用率磁盘的全部容量。
- 可靠性：不提供可靠性。

### 38.3 RAID 1级：镜像
生成每个块的一个副本，放在一个单独的磁盘上面，容许磁盘故障。
<div align="center"> <img src="https://cdn.nlark.com/yuque/0/2023/png/29674612/1681438473010-28dcb272-6f53-49db-bb6b-30543e0d2c53.png#averageHue=%23ededcc&clientId=u71374f12-77a8-4&from=ui&height=166&id=u3fc66edc&originHeight=227&originWidth=960&originalType=binary&ratio=1.5&rotation=0&showTitle=false&size=11068&status=done&style=none&taskId=u608eb692-80b5-4a03-b698-48261b8280f&title=&width=700" width="700" /> </div>



**RAID-1分析**

- 性能：对于单个读写请求：读取延迟和单个磁盘延迟一样，写延迟比当个磁盘略高（需要等待并行的两个物理写入，写延迟取决于延迟最大那个物理写入）。对于稳态吞吐量：顺序写入的最大带宽为$\frac{N}{2}S$，顺序读的带宽一样；随机写入的最大带宽$\frac{N}{2}R$，随机读带宽$NR$（数据本身和拷贝都可进行读）。
> **为什么顺序读的最大带宽只有**$\frac{N}{2}S$**？**
> 即使顺序读时，数据和拷贝都可以读，所有磁盘并行工作时，那么单个磁盘上面就不是顺序读了，需要跳过一些块（被跳过的块在备份磁盘上面被读取），跳过时实际上不会提供有用的带宽。

- 容量：只有磁盘容量的一半。
- 可靠性：对于处理当个磁盘故障很好。

### 38.4 RAID 4级：奇偶校验
这样方式试图用较少的容量克服镜像系统的巨大容量代价，付出的代价是性能的损失。
利用奇偶校验，只需一个磁盘进行存储冗余信息，如下图：
<div align="center"> <img src="https://cdn.nlark.com/yuque/0/2023/png/29674612/1681439469309-9ce96aac-4947-4668-927f-d82f6cb6fb63.png#averageHue=%23eeedec&clientId=u71374f12-77a8-4&from=ui&height=108&id=u35847aba&originHeight=148&originWidth=958&originalType=binary&ratio=1.5&rotation=0&showTitle=false&size=7710&status=done&style=none&taskId=u16857dee-3a61-46f9-9720-fa978aae565&title=&width=700" width="700" /> </div>


**RAID-4分析**

- 容量：可用容量为$N-1$。
- 可靠性：奇偶校验只能检测一个位的错误，而校验码中的每一个位来源一个硬盘，所以只容许一个磁盘故障。
- 性能：对于稳定吞吐量：
   - 就读取而言：顺序和随机读取性能分别为$(N-1)S$和$(N-1)R$；
   - 就写入而言：先分析奇偶校验码更新方法
> **加法奇偶校验**：需要读取同一条带上所有块，和新写入的块进行异或运算得出新的校验码。
> **减法奇偶校验**：核心思想是，如果新的块中的某一位相对于原来的块不变，新的校验位相对旧的校验位就不变，所以计算公式为$P_{new}=\left( C_{old}\oplus C_{new} \right) \oplus P_{old}$

进行顺序写入时，采用加法奇偶校验，条带化的磁盘可以并行工作，所以性能为$(N-1)S$。
进行随机写入时，采用减法奇偶校验更快，但是每次写入都要更新奇偶校验的磁盘，无法进行并行工作，奇偶校验的硬盘成了瓶颈，称为基于奇偶校验的RAID的小写入问题，奇偶校验硬盘为每个逻辑IO执行两次IO（读取，然后写入更新），性能为$\frac{1}{2}R$。
<div align="center"> <img src="https://cdn.nlark.com/yuque/0/2023/png/29674612/1681528632461-9bc3932c-a115-4f8a-a24f-4cd4190ead5e.png#averageHue=%23f0efef&clientId=u4244b9c7-e2a2-4&from=ui&height=158&id=uf407a24a&originHeight=325&originWidth=1438&originalType=binary&ratio=1.5&rotation=0&showTitle=false&size=27485&status=done&style=none&taskId=u6b3545cd-ca1e-44f2-abd6-5c8fbafdee7&title=&width=700" width="700" /> </div>



### 38.5 RAID 5级：旋转奇偶校验
为了解决基于奇偶校验的RAID的小写入问题，将奇偶校验码分散到各个硬盘中，以提高磁盘工作的并行性，如下图：
<div align="center"> <img src="https://cdn.nlark.com/yuque/0/2023/png/29674612/1681528885332-2d72b151-c697-42d6-a8e3-acb4f09962cd.png#averageHue=%23ecebeb&clientId=u4244b9c7-e2a2-4&from=ui&height=174&id=uc1c9dfba&originHeight=359&originWidth=1444&originalType=binary&ratio=1.5&rotation=0&showTitle=false&size=26058&status=done&style=none&taskId=uead72a80-8602-4e7e-b215-3e3aefe6614&title=&width=700" width="700" /> </div>


稳定吞吐量顺序读写能力和RAID 4级一样，对于随机读写：

- 随机读取：所有磁盘并行工作，读取性能为$NR$。
- 随机写入：可以跨请求进行必行处理（先处理在不同行的请求），当所有磁盘均匀忙碌时，性能为$\frac{N}{4}R$。4倍的损失——跨行并行工作，每个磁盘一次处理4个IO请求（数据的读写、校验码的读写）。

由于RAID5基本和RAID4基本一样，但性能更好，几乎完全取代了RAID4（除非在一些能够保证绝对不行进行小写入的场景）。

### 38.6 总结
<div align="center"> <img src="https://cdn.nlark.com/yuque/0/2023/png/29674612/1681529842860-52cb4e6f-53ea-4fec-a612-bcabfd6c22ae.png#averageHue=%23f5f5f4&clientId=u4244b9c7-e2a2-4&from=ui&height=369&id=u1d2fc63e&originHeight=633&originWidth=1201&originalType=binary&ratio=1.5&rotation=0&showTitle=false&size=42350&status=done&style=none&taskId=ua49dfdb5-ad11-4758-87e4-70566a1518c&title=&width=700" width="700" /> </div>




## 39章 插叙：文件和目录
进程，是虚拟化的CPU；地址空间，是虚拟化的内存。接下来讨论的是虚拟化的存储。
### 39.1 文件与目录
存储虚拟化有两个关键的抽象：

- 文件：每个文件都有低级的名称——inode号。
- 目录：也有低级的名称，但是内容什么具体，包括一个（用户可读名字-低级名字）列表，将用户可读名字映射到低级名称。

### 39.2 文件系统接口
**创建文件**
在Linux系统中，创建文件有多种方式，但是底层是调用`open`或`openat`系统调用实现。`open`系统调用返回一个文件描述符（file desriptor）。
文件描述符是每个进程私有的，用于访问文件。每个运行进程的进程都已经打开了3个文件——标准输入`0`、标准输出`1`、标准错误`2`，当第一打开文件时一般返回的文件描述符都为`3`。

**读写文件**
进行读取文件时，利用`strace`工具可查看程序使用的系统调用。以读取一个内容为`hello`的文件`test.txt`为例：
<div align="center"> <img src="https://cdn.nlark.com/yuque/0/2023/png/29674612/1681957939688-b9f98f73-672f-47eb-9d4e-2b292db2e312.png#averageHue=%23f0f0f0&clientId=ub5ed1480-a12f-4&from=ui&height=242&id=ucb051309&originHeight=393&originWidth=1135&originalType=binary&ratio=1.5&rotation=0&showTitle=false&size=76711&status=done&style=none&taskId=ud41e1cd5-c4f5-4112-bfc6-567cf50ffdf&title=&width=700" width="700" /> </div>


对于`read`系统调用：

- 第一个参数为文件描述符。
- 第二个参数指向用于存放读取结果的缓冲区，此处`strace`工具已经把缓冲区内容显示出来。
- 第三个参数为缓冲区大小，单位为字节。
- 返回值为读取的字节数。

用`lseek`调用进行不按顺序的读取和写入：

- 第一个参数为文件描述符。
- 第二个参数为偏移量，将文件定位到特定位置。
- 第三个参数指定搜索方式：

<div align="center"> <img src="https://cdn.nlark.com/yuque/0/2023/png/29674612/1681958491096-bc273199-54ba-4928-a5fb-3f6c9bca2d13.png#averageHue=%23fbfaf9&clientId=ub5ed1480-a12f-4&from=ui&height=120&id=u264ed513&originHeight=173&originWidth=1009&originalType=binary&ratio=1.5&rotation=0&showTitle=false&size=12565&status=done&style=none&taskId=u541e7b9f-f8d7-435d-b3e3-47105293b96&title=&width=700" width="700" /> </div>



调用`write`时，由于性能的原因不会立即写入。UNIX提供了`fsync(int fd)`，针对特定文件描述符调用`fsync`时，文件系统强制将所有脏数据写入硬盘。

**文件重命名**
`mv`使用了系统调用`rename`来修改文件名字。有两个参数`rename(char* old ,char* new)`。`rename`（通常）是一个原子的调用，不会出现奇怪的中间状态，对于需要对文件状态进行原子更新的应用程序很重要，如下：
<div align="center"> <img src="https://cdn.nlark.com/yuque/0/2023/png/29674612/1681959839593-d4e07c07-9b03-4a8d-b0c7-ae40aa756d26.png#averageHue=%23fcfbfa&clientId=ub5ed1480-a12f-4&from=ui&height=135&id=ub4af75c6&originHeight=182&originWidth=947&originalType=binary&ratio=1.5&rotation=0&showTitle=false&size=11121&status=done&style=none&taskId=uffcd82f3-2b0f-46c5-8d51-1c0a8d32c79&title=&width=700" width="700" /> </div>


以上程序先创建了一个新的文件，将数据写入新文件后，最后一步自动将新文件交换到位，同时删除旧版本的文件，实现原子文件更新。

**获取文件信息**
文件系统保存关于正在存储的文件的大量信息，这些数据被称为文件元数据（metadata）。通过`stat`或`fstat`系统调用，将在一个文件中填充一个`stat`结构：
<div align="center"> <img src="https://cdn.nlark.com/yuque/0/2023/png/29674612/1681960411138-5e36c2df-6395-472a-b156-88b00dc4cb81.png#averageHue=%23fcfcfb&clientId=ub5ed1480-a12f-4&from=ui&height=302&id=u713e4cd1&originHeight=503&originWidth=1167&originalType=binary&ratio=1.5&rotation=0&showTitle=false&size=31763&status=done&style=none&taskId=ua15d4e81-3d85-42bf-bb03-e6d8fc8a3a6&title=&width=700" width="700" /> </div>


可以使用命令行工具`stat`查看这些信息。

**删除文件**
用命令行工具`rm`删除文件，底层调用了`unlink`或`unlinkat`系统调用来实现。
> 关于命令行工具`rm`
> - `rm *`：删除当前目录所有文件。
> - `rm -rf *`：删除当前目录下文件和目录（递归进行操作）。

空目录包含两个条目：

- `.`：引用自身的条目。
- `..`：引用父目录的条目。

**读取目录**
`ls`工具依靠`opendir``readdir``closedir`调用实现，一个例子如下：
<div align="center"> <img src="https://cdn.nlark.com/yuque/0/2023/png/29674612/1681968066250-c5439d26-a21c-4a1f-a097-0adb885d1698.png#averageHue=%23fdfdfc&clientId=ub5ed1480-a12f-4&from=ui&height=218&id=u34144099&originHeight=322&originWidth=1035&originalType=binary&ratio=1.5&rotation=0&showTitle=false&size=13822&status=done&style=none&taskId=u23e41d15-5528-4372-9ca5-29e2f9c60d0&title=&width=700" width="700" /> </div>


`dirent`的声明如下：
<div align="center"> <img src="https://cdn.nlark.com/yuque/0/2023/png/29674612/1681968414663-b09f1bfa-208f-4ab5-83b9-f81c08b3ad24.png#averageHue=%23fdfcfc&clientId=ub5ed1480-a12f-4&from=ui&height=171&id=u1b5f3c16&originHeight=253&originWidth=1036&originalType=binary&ratio=1.5&rotation=0&showTitle=false&size=12852&status=done&style=none&taskId=u6379acfa-b260-4cd9-aeaa-1fe1c904992&title=&width=700" width="700" /> </div>



**删除目录**
可使用`rm -d`命令删除。对于空目录，还可以使用`rmdir`命令删除。

**硬连接**
在文件系统树中创建条目的方法——通过`link`系统调用。`link`有两个参数：一个旧路径名、一个新路径名。实际上就是将一个文件名链接到一个旧路径文件名上面，指向同一个文件，不对文件进行复制。新文件和旧文件本质上没有任何区别，都是指向文件底层元数据的链接。
可以通过命令行工具`ln`执行次操作。每次链接文件时，会使文件的引用计数加一，而取消链接时使引用计数减一，当引用计数减为0时，文件系统释放内存删除文件。
<div align="center"> <img src="https://cdn.nlark.com/yuque/0/2023/png/29674612/1681970009178-d700b3be-b68f-468f-9d94-a06c8fc3f0c3.png#averageHue=%23f1f1f0&clientId=ub5ed1480-a12f-4&from=ui&height=282&id=u7d1f63ad&originHeight=445&originWidth=1105&originalType=binary&ratio=1.5&rotation=0&showTitle=false&size=39472&status=done&style=none&taskId=ua092cd99-d5c0-4acc-96c9-a64edfb48e4&title=&width=700" width="700" /> </div>



**符号链接**
硬链接的局限：

- 无法创建目录的硬链接（可能会在目录树中创建一个环）。
- 不能硬链接到其他磁盘分区中的文件（inode在特定文件系统中唯一，不能跨文件系统）。

软链接实际上是一种不同类型的文件，如下图：
<div align="center"> <img src="https://cdn.nlark.com/yuque/0/2023/png/29674612/1682037817841-bb9186d6-0239-49ba-8986-210ac751c54f.png#averageHue=%23eeeeee&clientId=uec87f155-f096-4&from=ui&height=554&id=u367c2dd3&originHeight=915&originWidth=1156&originalType=binary&ratio=1.5&rotation=0&showTitle=false&size=93023&status=done&style=none&taskId=u5799fe40-7653-4b34-abd9-a7974583296&title=&width=700" width="700" /> </div>


符号链接将指向的文件的路径名作为连接文件的数据。如上图符号链接的大小为8字节，对应路径名`text.txt`，访问一个符号链接时实际访问的是该路径名的文件。

**创建并挂载文件系统**
文件系统是组织和管理数据和文件的操作系统，Linux系统通过目录树来进行文件的操作，系统启动之后，根目录自动挂载。想要通过目录树来访问某个磁盘，现在磁盘上建立文件系统，然后将文件系统挂载到根目录或者根目录某个目录下。
创建文件系统的工具`mkfs`，该命令需要一个设备（磁盘）和文件系统类型，然后在磁盘分区上写入空的文件系统。
用命令`mount`将文件系统挂载到目录树上，如下图：
<div align="center"> <img src="https://cdn.nlark.com/yuque/0/2023/png/29674612/1682038980469-68e05ec0-528e-450d-a3c6-9c4560403648.png#averageHue=%23fbfbfa&clientId=uec87f155-f096-4&from=ui&height=56&id=ue9735da3&originHeight=83&originWidth=1037&originalType=binary&ratio=1.5&rotation=0&showTitle=false&size=23123&status=done&style=none&taskId=u3de79e05-cd07-4e93-acc7-92b9324e519&title=&width=700" width="700" /> </div>




## 40章 文件系统实现
本章介绍一个简单文件系统的实现——VSFS（Very Simple File System，简单文件系统），是典型UNIX文件系统的简化版本。
文件系统是纯软件，不会添加硬件功能来提升文件系统性能，但需要注意设备的特性，以确保文件系统能够运行良好。
### 40.1 思考方式
对于一个文件系统需要考虑两个方面内容：

- 数据结构：文件系统在磁盘上使用哪些数据结构来组织数据和元数据。
- 访问方式：对应进程的调用，如何映射到结构上面，如何读取结构，应该修改哪些结构。

### 40.2 整体组织
**分块**
先将磁盘分成块（block），简单的文件系统只使用一种块大小。这里以最常用的4KB为例。

**分区域**

- 数据区域：存放用户数据的区域。
- inode表：存放inode的区域。inode中记录文件的信息。
- 分配记录：可以用空闲列表记录，即指向第一个空闲块，然后空闲块指向下一个空闲块。这里使用位图（bitmap）每个位用于指示相应的对象是空闲`0`还是被使用`1`。
- 超级块（superblock）：包含文件系统的信息，当挂载文件系统时，操作系统首先读取超级块，初始化参数，然后将该卷添加到文件系统树中。

<div align="center"> <img src="https://cdn.nlark.com/yuque/0/2023/png/29674612/1682045769262-afa2a5a3-f56e-4953-8bdc-c5064db20515.png#averageHue=%23e2e2e2&clientId=uec87f155-f096-4&from=ui&height=117&id=u6d8ac06f&originHeight=174&originWidth=1037&originalType=binary&ratio=1.5&rotation=0&showTitle=false&size=10651&status=done&style=none&taskId=ud943fabf-dfdc-44ec-86e3-36af9d4c4f6&title=&width=700" width="700" /> </div>



### 40.3 文件组织：inode
**inode结构**
inode是index node的简称。每个inode结构体中保存着文件的信息（文件类型、大小、分块的块数、保护信息、时间信息），这些信息称为元数据（metadata），文件系统中除了纯粹的用户数据，其他的信息都被称为元数据。
每个inode结构都由一个数字（inumber）隐式引用，通过inumber可计算出inode结构体在inode表中的位置。假设每个inode大小为256字节，VSFS分区如下：
<div align="center"> <img src="https://cdn.nlark.com/yuque/0/2023/png/29674612/1682046392432-965945a0-5eb5-45a7-85c8-b20f1c672180.png#averageHue=%23d2d2d2&clientId=uec87f155-f096-4&from=ui&height=133&id=OHSSM&originHeight=213&originWidth=1122&originalType=binary&ratio=1.5&rotation=0&showTitle=false&size=20844&status=done&style=none&taskId=ud3ca3740-4a5b-46e3-b826-3e2d0e53815&title=&width=700" width="700" /> </div>



**直接索引**
设计inode时最重要的决定之一就是如何引用数据块的位置。
一个简单的方法是，在inode中设置一个或多个直接指针，每个指针直接指向文件所用到的数据块。这种方法不使用大型的文件（$文件大小>直接指针数量\times 每个块的大小$）。

**基于范围**
另一种方法是使用范围——使用一个指针和一个长度（以块为单位）就可以确定文件的位置。
只有一个范围是局限的——分配文件是可能无法找到连续的磁盘可用块，因此具有范围的文件系统通常允许设置一个范围，给文件系统在分配空间上更多自由。
基于指针的方法灵活，但是使用大量元数据；基于范围的方法不够灵活，但是更紧凑。

**多级索引**
为了支持更大的文件，在inode中有固定数量的直接指针（例如12个）和一个间接指针（indirect pointer），当文件足够大时，会分配一个间接块（来自磁盘的数据块区域），然后将间接指针指向该间接块，间接块中存储的是指针，指向数据块。假如地址为4字节，那么文件最大可以增长到$(12+1024)\times 4KB=4144KB$。
如果还需要支持更大的文件，只需添加一个双重间接指针（double indirect pointer），指向包含间接指针的块，此时允许使用$1024\times 1024$个块来保存文件，超过$4GB$。
<div align="center"> <img src="https://cdn.nlark.com/yuque/0/2023/jpeg/29674612/1682055484418-47a68179-7477-4473-ab93-bac1efab3d7b.jpeg#averageHue=%23fcfcfc&clientId=uec87f155-f096-4&from=ui&height=255&id=u6faa0e3a&originHeight=508&originWidth=1393&originalType=binary&ratio=1.5&rotation=0&showTitle=false&size=47596&status=done&style=none&taskId=ue01e138f-5dd0-43b8-921f-6f0111ed324&title=&width=700" width="700" /> </div>


这种不平衡树的方式被称为文件块的多级索引（multi-level index）方法。大多数文件较小可以用直接指针，当文件足够大时，才采用间接指针。

**基于链接的方法**
设计inode另一个简单的方法——链表。在一个inode中只需要一个指针，指向文件第一个块，然后在该数据块末尾添加一个指针。这种链接式文件分配（隐式链接），对于随机访问或者只读取文件后面的块，效率很低。
为了使链接式更好的工作，一些系统在内存中保存链接信息表，而不是将下一个指针和数据块本身一起存储。该表用数据块D的地址来索引，第一个条目就是D后面下一个块的地址（显示链接）。这就是所谓的文件分配表（File Allocation Table ，FAT）——文件系统的基本组织。

### 40.4 组织目录
目录的组织很简单，一个目录基本上值包含一个二元组（条目名称、inode号）的列表，如下如：
<div align="center"> <img src="https://cdn.nlark.com/yuque/0/2023/png/29674612/1682056923273-73179ab0-ad57-41ac-9012-f991f463b21b.png#averageHue=%23fefdfd&clientId=uec87f155-f096-4&from=ui&height=130&id=ub255a70c&originHeight=216&originWidth=828&originalType=binary&ratio=1.5&rotation=0&showTitle=false&size=5363&status=done&style=none&taskId=ucda79a23-b771-4192-aea7-a5320b72f9b&title=&width=500" width="500" /> </div>



- strlen：名称的实际长度。
- reclen：“记录长度”，即保存该条目名称的地方的实际空间。该项设置的原因如下：

删除一个文件会在目录中间留下一段空白空间，此时可标记其为空（例如可用一个保留的inode号，0），如果该目录下新建文件，有可能会在填补该空白空间，新条目可能会重复使用旧的、更大的条目，此时会有额外的空间。
线性目录列表并不是存储目录的唯一方法，XFS以B树形式存储目录，文件创建操作更快。
<div align="center"> <img src="https://cdn.nlark.com/yuque/0/2023/png/29674612/1682561672334-7ddbc847-3661-4b63-9dae-89f3488eb512.png#averageHue=%23f7f7f7&clientId=ue944bde8-82df-4&from=ui&height=282&id=u614b0c41&originHeight=495&originWidth=1229&originalType=binary&ratio=1.5&rotation=0&showTitle=false&size=66359&status=done&style=none&taskId=ubcb1c7df-6e45-4e61-a6f5-71a80f80dcf&title=&width=700" width="700" /> </div>



### 40.5 空闲空间管理
在之前的例子中，使用了位图进行空间管理。管理空闲空间的方法有很多：

- 一些早期文件管理系统使用空闲列表。
- 现代文件系统使用更复杂的数据结构，例如XFS使用B树来紧凑表示磁盘哪些块是空的。

预分配策略：文件系统保证文件的一部分将在磁盘上时连续的，从而提高性能。

### 40.6 访问路径
**从磁盘读取文件**
为了找到文件的inode，文件系统从根目录开始路径名，在大多数UNIX系统中，根的inode号为2，所以一开始文件系统读入inode号为2的块。然后对块中的每个条目进行`read`调用，知道直到对应的文件目录。
对于路径每个增加的目录都必须读取他inode及其数据，对于大型目录，需要读取很多inode块才能找到所需条目。

**写入磁盘**
文件写入磁盘也需要打开文件。读取文件已经需要多个IO操作来，写入文件在此基础上，还需要更多的操作：

- 分配内存所需操作：读取inode位图，写入inode位图。
- 写入一个新的inode结构。
- 写入目录，将文件的名称连接到inode号。

### 40.7 缓存和缓冲
为了缓解读取和写入文件带来的性能问题，大多数文件系统积极使用系统内存（DRAM）来缓存重要的块，减少磁盘IO操作。
早期文件系统采用静态内存划分方法——引入一个固定大小的缓存来保存常用的块，这种方法可能会导致内存的浪费。
现代系统采用动态划分的方法——将虚拟内存页面和文件系统页面集成到统一页面缓存（unified page cache）中，这样可以在虚拟内存和文件系统之间灵活分配内存。

缓存可以减少甚至避免读取磁盘文件时的IO，但是写入流量必须进入磁盘，才能实现持久化，因此Cache并不能减少写入流量。
写缓冲——通过延迟写入，将一些更新组成一批更新，系统可以调度后续IO，从而提升性能。例如创建一个文件时，位图被更新，稍后又创建一个文件，位图又会被更新，可以将两次更新合并为一次，减少IO。所以，大多数现代文件管理系统会将写入在内存中缓冲5-30s。

---








